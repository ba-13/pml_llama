{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.convert_parameters import parameters_to_vector\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import time\n",
    "from torch.func import functional_call, jacrev\n",
    "from torch.distributions.multivariate_normal import _precision_to_scale_tril\n",
    "\n",
    "from custom_laplace import Subnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.random.manual_seed(113311)\n",
    "np.random.seed(113311)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperparams import (\n",
    "    lr,\n",
    "    acquisition_batch_size,\n",
    "    train_batch_size,\n",
    "    num_train,\n",
    "    num_pool,\n",
    ")\n",
    "\n",
    "pool_batch_size = 1\n",
    "count_subnet = 1000\n",
    "sigma_noise = 1.0\n",
    "temperature = 1.0\n",
    "\n",
    "epochs = 25  # training epochs\n",
    "num_epochs_variance_train = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "H_factor = 1 / (sigma_noise**2) / temperature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model_, train_loader, optimizer):\n",
    "    model_.train()\n",
    "    avg_loss = 0\n",
    "    epoch_size = 0\n",
    "    for _, (data, target) in enumerate(train_loader):\n",
    "        epoch_size += 1\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model_(data)\n",
    "        loss = F.cross_entropy(output, target)\n",
    "        avg_loss += loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return avg_loss / epoch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model_, test_loader):\n",
    "    model_.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model_(data)\n",
    "            test_loss += F.cross_entropy(\n",
    "                output, target, reduction=\"sum\"\n",
    "            ).item()  # sum up batch loss\n",
    "            pred = output.argmax(\n",
    "                dim=1, keepdim=True\n",
    "            )  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    return correct, test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_losses(epoch, train_loss, test_loss, correct, total):\n",
    "    test_accuracy = correct / float(total)\n",
    "    print(\n",
    "        \"For epoch {}: Train - Avg loss: {:.4f}; Test - Avg loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\".format(\n",
    "            epoch, train_loss, test_loss, correct, total, 100.0 * test_accuracy\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hasnan(x):\n",
    "    return torch.isnan(x).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_occurrences_from_list(l, items):\n",
    "    return list(\n",
    "        np.setdiff1d(\n",
    "            np.array(l, dtype=int), np.array(items, dtype=int), assume_unique=True\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_data(indices, from_subset, to_subset):\n",
    "    from_subset.indices = remove_occurrences_from_list(from_subset.indices, indices)\n",
    "    if isinstance(to_subset.indices, list):\n",
    "        to_subset.indices.extend(indices)\n",
    "    elif isinstance(to_subset.indices, np.ndarray):\n",
    "        to_subset.indices = np.concatenate([to_subset.indices, np.array(indices)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(50000, 45000, 10000)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = datasets.CIFAR10(\n",
    "    \"data\", train=True, download=True, transform=transforms.ToTensor()\n",
    ")\n",
    "\n",
    "classes = dataset.classes\n",
    "\n",
    "train_size = int(0.90 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(\n",
    "    dataset, [train_size, test_size]\n",
    ")\n",
    "\n",
    "test_dataset = datasets.CIFAR10(\n",
    "    \"data\", train=False, download=True, transform=transforms.ToTensor()\n",
    ")\n",
    "len(dataset), len(train_dataset), len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(classes)\n",
    "samples_per_class = (num_train) // num_classes\n",
    "\n",
    "class_indices = defaultdict(list)\n",
    "\n",
    "for idx, (_, target) in enumerate(train_dataset):\n",
    "    class_indices[target].append(idx)\n",
    "\n",
    "for indices in class_indices.values():\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "train_indices = []\n",
    "\n",
    "# get samples_per_class for all classes\n",
    "for indices in class_indices.values():\n",
    "    till = min(len(indices), samples_per_class)\n",
    "    train_indices.extend(indices[:till])\n",
    "\n",
    "np.random.shuffle(train_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 44800)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_indices = np.arange(len(train_dataset))\n",
    "remaining_indices = np.setdiff1d(all_indices, train_indices)\n",
    "pool_indices = np.random.choice(remaining_indices, size=num_pool, replace=False)\n",
    "len(pool_indices), len(remaining_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of common elements: 0\n"
     ]
    }
   ],
   "source": [
    "common_elements = np.intersect1d(train_indices, pool_indices)\n",
    "num_common_elements = len(common_elements)\n",
    "print(f\"Number of common elements: {num_common_elements}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrain_dataset = torch.utils.data.Subset(dataset, train_indices)\n",
    "pool_dataset = torch.utils.data.Subset(dataset, pool_indices)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_dataset, batch_size=train_batch_size, pin_memory=True, shuffle=True\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset, batch_size=train_batch_size, pin_memory=True, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrain_loader = torch.utils.data.DataLoader(\n",
    "    pretrain_dataset, batch_size=train_batch_size, pin_memory=True, shuffle=True\n",
    ")\n",
    "\n",
    "model = Net().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "subnet = Subnet(model, snapshot_freq=1, count_params_subnet=count_subnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For epoch 0: Train - Avg loss: 2.3122; Test - Avg loss: 2.3047, Accuracy: 500/5000 (10%)\n",
      "For epoch 1: Train - Avg loss: 2.2777; Test - Avg loss: 2.3142, Accuracy: 500/5000 (10%)\n",
      "For epoch 2: Train - Avg loss: 2.2666; Test - Avg loss: 2.3543, Accuracy: 559/5000 (11%)\n",
      "For epoch 3: Train - Avg loss: 2.3130; Test - Avg loss: 2.3149, Accuracy: 506/5000 (10%)\n",
      "For epoch 4: Train - Avg loss: 2.2789; Test - Avg loss: 2.3063, Accuracy: 557/5000 (11%)\n",
      "For epoch 5: Train - Avg loss: 2.2948; Test - Avg loss: 2.3098, Accuracy: 463/5000 (9%)\n",
      "For epoch 6: Train - Avg loss: 2.2653; Test - Avg loss: 2.3141, Accuracy: 506/5000 (10%)\n",
      "For epoch 7: Train - Avg loss: 2.2363; Test - Avg loss: 2.3621, Accuracy: 507/5000 (10%)\n",
      "For epoch 8: Train - Avg loss: 2.3057; Test - Avg loss: 2.3386, Accuracy: 507/5000 (10%)\n",
      "For epoch 9: Train - Avg loss: 2.2644; Test - Avg loss: 2.3085, Accuracy: 739/5000 (15%)\n",
      "For epoch 10: Train - Avg loss: 2.2812; Test - Avg loss: 2.3082, Accuracy: 580/5000 (12%)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[60], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs \u001b[38;5;241m-\u001b[39m num_epochs_variance_train):\n\u001b[1;32m      4\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m train(model, pretrain_loader, optimizer)\n\u001b[0;32m----> 5\u001b[0m     correct, test_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     print_losses(epoch, train_loss, test_loss, correct, total)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting variance training for subnet selection\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[49], line 6\u001b[0m, in \u001b[0;36mtest\u001b[0;34m(model_, test_loader)\u001b[0m\n\u001b[1;32m      4\u001b[0m correct \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m----> 6\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m data, target \u001b[38;5;129;01min\u001b[39;00m test_loader:\n\u001b[1;32m      7\u001b[0m         data, target \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mto(device), target\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      8\u001b[0m         output \u001b[38;5;241m=\u001b[39m model_(data)\n",
      "File \u001b[0;32m~/anaconda3/envs/conda-torch/lib/python3.10/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/envs/conda-torch/lib/python3.10/site-packages/torch/utils/data/dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/anaconda3/envs/conda-torch/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__getitems__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__getitems__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n",
      "File \u001b[0;32m~/anaconda3/envs/conda-torch/lib/python3.10/site-packages/torch/utils/data/dataset.py:364\u001b[0m, in \u001b[0;36mSubset.__getitems__\u001b[0;34m(self, indices)\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 364\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx]] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n",
      "File \u001b[0;32m~/anaconda3/envs/conda-torch/lib/python3.10/site-packages/torch/utils/data/dataset.py:364\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 364\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n",
      "File \u001b[0;32m~/anaconda3/envs/conda-torch/lib/python3.10/site-packages/torchvision/datasets/cifar.py:115\u001b[0m, in \u001b[0;36mCIFAR10.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    111\u001b[0m img, target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[index], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtargets[index]\n\u001b[1;32m    113\u001b[0m \u001b[38;5;66;03m# doing this so that it is consistent with all other datasets\u001b[39;00m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;66;03m# to return a PIL Image\u001b[39;00m\n\u001b[0;32m--> 115\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfromarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    118\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(img)\n",
      "File \u001b[0;32m~/anaconda3/envs/conda-torch/lib/python3.10/site-packages/PIL/Image.py:3089\u001b[0m, in \u001b[0;36mfromarray\u001b[0;34m(obj, mode)\u001b[0m\n\u001b[1;32m   3087\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m strides \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3088\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(obj, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtobytes\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 3089\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtobytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3090\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3091\u001b[0m         obj \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39mtostring()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "total = len(val_dataset)\n",
    "\n",
    "for epoch in range(epochs - num_epochs_variance_train):\n",
    "    train_loss = train(model, pretrain_loader, optimizer)\n",
    "    correct, test_loss = test(model, val_loader)\n",
    "    print_losses(epoch, train_loss, test_loss, correct, total)\n",
    "\n",
    "print(\"Starting variance training for subnet selection\")\n",
    "for epoch in range(num_epochs_variance_train):\n",
    "    train_loss = train(model, pretrain_loader, optimizer)\n",
    "    correct, test_loss = test(model, val_loader)\n",
    "    print_losses(epoch, train_loss, test_loss, correct, total)\n",
    "    subnet.update_model_variances(epoch, epochs)\n",
    "\n",
    "correct, test_loss = test(model, test_loader)\n",
    "print(f\"Test loss: {test_loss}; Accuracy {correct}/{len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"./tmp/model_ppd.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2374, 2.110188164138794)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.load(\"./tmp/model_ppd.pth\")\n",
    "test(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dicts(model):\n",
    "    params_dict = {k: v for k, v in model.named_parameters() if v.requires_grad}\n",
    "    buffers_dict = {k: v for k, v in model.named_buffers()}\n",
    "\n",
    "    params_dict = {key: value.to(device) for key, value in params_dict.items()}\n",
    "    buffers_dict = {key: value.to(device) for key, value in buffers_dict.items()}\n",
    "    return params_dict, buffers_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X, _ = next(iter(val_loader))\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     try:\n",
    "#         out = model(X[:1].to(device))\n",
    "#     except (TypeError, AttributeError):\n",
    "#         out = model(X.to(device))\n",
    "\n",
    "# n_outputs = out.shape[-1]\n",
    "# setattr(model, \"output_size\", n_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(x, eps=1e-6):\n",
    "    return -(x + eps) * torch.log(x + eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jacobians(x, params_dict, buffers_dict, subnet_mask_indices):\n",
    "    def model_fn_params_only(params_dict, buffers_dict):\n",
    "        out = functional_call(model, (params_dict, buffers_dict), x)\n",
    "        return out, out\n",
    "\n",
    "    with torch.no_grad():\n",
    "        Js, f = jacrev(model_fn_params_only, has_aux=True)(params_dict, buffers_dict)\n",
    "\n",
    "    Js = [\n",
    "        j.flatten(start_dim=-p.dim()) for j, p in zip(Js.values(), params_dict.values())\n",
    "    ]\n",
    "    Js = torch.cat(Js, dim=-1)\n",
    "\n",
    "    Js = Js[:, :, subnet_mask_indices]\n",
    "    return Js, f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ppd_score(ppd):\n",
    "    # I(y;W | x) = H1 - H2 = H(y|x) - E_w[H(y|x,W)]\n",
    "    H1 = entropy(ppd).sum(axis=1)\n",
    "    return H1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_batch(model, pool_data, subnet_mask_indices, posterior_covariance):\n",
    "    pool_loader = torch.utils.data.DataLoader(\n",
    "        pool_data, batch_size=pool_batch_size, pin_memory=True, shuffle=False\n",
    "    )\n",
    "    params_dict, buffers_dict = generate_dicts(model)\n",
    "\n",
    "    def calculate_ppd(X):\n",
    "        Js, f_mu = jacobians(X, params_dict, buffers_dict, subnet_mask_indices)\n",
    "        Js = Js.squeeze(0)\n",
    "        f_var = torch.einsum(\"np,pq,mq->nm\", Js, posterior_covariance, Js)\n",
    "        f_var = f_var.unsqueeze(0)\n",
    "        kappa = 1 / torch.sqrt(1.0 + torch.pi / 8 * f_var.diagonal(dim1=1, dim2=2))\n",
    "        final_ppd = torch.softmax(kappa * f_mu, dim=-1)\n",
    "        return final_ppd\n",
    "\n",
    "    scores = torch.zeros(len(pool_data)).to(device)\n",
    "    for batch_idx, (data, _) in enumerate(pool_loader):\n",
    "        end_idx = batch_idx + data.shape[0]\n",
    "        ppd = calculate_ppd(data.to(device))\n",
    "        scores[batch_idx:end_idx] = ppd_score(ppd)\n",
    "\n",
    "    best_local_indices = torch.argsort(scores, descending=True)[:acquisition_batch_size]\n",
    "    best_global_indices = np.array(pool_data.indices)[best_local_indices.cpu().numpy()]\n",
    "    return best_global_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_posterior_covariance(H):\n",
    "    prior_precision_diag = torch.ones(count_subnet, device=device)\n",
    "    # prior with lambda = 1\n",
    "    posterior_precision = H_factor * H + torch.diag(prior_precision_diag)\n",
    "    invsqrt_precision = _precision_to_scale_tril\n",
    "    posterior_scale = invsqrt_precision(posterior_precision)\n",
    "    posterior_covariance = posterior_scale @ posterior_scale.T\n",
    "    return posterior_covariance\n",
    "\n",
    "\n",
    "def calculate_ggn(model, train_dataset, subnet_mask_indices):\n",
    "    params_dict, buffers_dict = generate_dicts(model)\n",
    "    H = torch.zeros(count_subnet, count_subnet, device=device)\n",
    "    loss = 0.0\n",
    "    lossfunc = nn.CrossEntropyLoss(reduction=\"sum\")\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=1, pin_memory=True, shuffle=True\n",
    "    )\n",
    "    for X, y in train_loader:\n",
    "        model.zero_grad()\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        Js, f = jacobians(X, params_dict, buffers_dict, subnet_mask_indices)\n",
    "        ps = torch.softmax(f, dim=-1)\n",
    "        H_lik = torch.diag_embed(ps) - torch.einsum(\"mk,mc->mck\", ps, ps)\n",
    "        H_batch = torch.einsum(\"bcp,bck,bkq->pq\", Js, H_lik, Js)\n",
    "        loss_batch = 1.0 * lossfunc(f, y)\n",
    "        loss += loss_batch\n",
    "        H += H_batch\n",
    "    posterior_covariance = get_posterior_covariance(H)\n",
    "    return posterior_covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For epoch 0: Train - Avg loss: 2.3125; Test - Avg loss: 2.3022, Accuracy: 697/5000 (14%)\n",
      "For epoch 1: Train - Avg loss: 2.2913; Test - Avg loss: 2.3011, Accuracy: 735/5000 (15%)\n",
      "For epoch 2: Train - Avg loss: 2.2943; Test - Avg loss: 2.3010, Accuracy: 633/5000 (13%)\n",
      "For epoch 3: Train - Avg loss: 2.2607; Test - Avg loss: 2.3005, Accuracy: 736/5000 (15%)\n",
      "For epoch 4: Train - Avg loss: 2.2083; Test - Avg loss: 2.3139, Accuracy: 506/5000 (10%)\n",
      "For epoch 5: Train - Avg loss: 2.2500; Test - Avg loss: 2.2776, Accuracy: 708/5000 (14%)\n",
      "For epoch 6: Train - Avg loss: 2.2381; Test - Avg loss: 2.2536, Accuracy: 752/5000 (15%)\n",
      "For epoch 7: Train - Avg loss: 2.2097; Test - Avg loss: 2.2287, Accuracy: 901/5000 (18%)\n",
      "For epoch 8: Train - Avg loss: 2.2049; Test - Avg loss: 2.2329, Accuracy: 840/5000 (17%)\n",
      "For epoch 9: Train - Avg loss: 2.1574; Test - Avg loss: 2.2221, Accuracy: 860/5000 (17%)\n",
      "For epoch 10: Train - Avg loss: 2.1075; Test - Avg loss: 2.2205, Accuracy: 874/5000 (17%)\n",
      "For epoch 11: Train - Avg loss: 2.0399; Test - Avg loss: 2.2285, Accuracy: 927/5000 (19%)\n",
      "For epoch 12: Train - Avg loss: 2.0820; Test - Avg loss: 2.1891, Accuracy: 934/5000 (19%)\n",
      "For epoch 13: Train - Avg loss: 2.1570; Test - Avg loss: 2.1766, Accuracy: 949/5000 (19%)\n",
      "For epoch 14: Train - Avg loss: 2.0253; Test - Avg loss: 2.1551, Accuracy: 1092/5000 (22%)\n",
      "For epoch 15: Train - Avg loss: 2.1734; Test - Avg loss: 2.1525, Accuracy: 1072/5000 (21%)\n",
      "For epoch 16: Train - Avg loss: 2.0368; Test - Avg loss: 2.1914, Accuracy: 837/5000 (17%)\n",
      "For epoch 17: Train - Avg loss: 2.0221; Test - Avg loss: 2.2773, Accuracy: 945/5000 (19%)\n",
      "For epoch 18: Train - Avg loss: 2.1074; Test - Avg loss: 2.1564, Accuracy: 988/5000 (20%)\n",
      "For epoch 19: Train - Avg loss: 1.9768; Test - Avg loss: 2.1421, Accuracy: 1019/5000 (20%)\n",
      "For epoch 20: Train - Avg loss: 2.0959; Test - Avg loss: 2.1676, Accuracy: 1042/5000 (21%)\n",
      "For epoch 21: Train - Avg loss: 2.0587; Test - Avg loss: 2.1422, Accuracy: 1009/5000 (20%)\n",
      "For epoch 22: Train - Avg loss: 2.0523; Test - Avg loss: 2.1159, Accuracy: 1112/5000 (22%)\n",
      "For epoch 23: Train - Avg loss: 2.0285; Test - Avg loss: 2.0921, Accuracy: 1164/5000 (23%)\n",
      "For epoch 24: Train - Avg loss: 1.9928; Test - Avg loss: 2.0882, Accuracy: 1117/5000 (22%)\n",
      "Test loss: 2.0721598945617674; Accuracy 2282/10000\n",
      "Acquiring BALD batch. acq_num: 1 Pool size: 10000\n",
      "Time taken for acquisition score computation: 53.596144676208496\n",
      "For epoch 0: Train - Avg loss: 2.2996; Test - Avg loss: 2.3048, Accuracy: 504/5000 (10%)\n",
      "For epoch 1: Train - Avg loss: 2.2689; Test - Avg loss: 2.3203, Accuracy: 504/5000 (10%)\n",
      "For epoch 2: Train - Avg loss: 2.2576; Test - Avg loss: 2.2859, Accuracy: 504/5000 (10%)\n",
      "For epoch 3: Train - Avg loss: 2.2170; Test - Avg loss: 2.2559, Accuracy: 513/5000 (10%)\n",
      "For epoch 4: Train - Avg loss: 2.2017; Test - Avg loss: 2.2794, Accuracy: 517/5000 (10%)\n",
      "For epoch 5: Train - Avg loss: 2.1889; Test - Avg loss: 2.2206, Accuracy: 599/5000 (12%)\n",
      "For epoch 6: Train - Avg loss: 2.2039; Test - Avg loss: 2.2568, Accuracy: 663/5000 (13%)\n",
      "For epoch 7: Train - Avg loss: 2.2543; Test - Avg loss: 2.2744, Accuracy: 635/5000 (13%)\n",
      "For epoch 8: Train - Avg loss: 2.2121; Test - Avg loss: 2.2308, Accuracy: 607/5000 (12%)\n",
      "For epoch 9: Train - Avg loss: 2.1466; Test - Avg loss: 2.2102, Accuracy: 910/5000 (18%)\n",
      "For epoch 10: Train - Avg loss: 2.1127; Test - Avg loss: 2.1859, Accuracy: 908/5000 (18%)\n",
      "For epoch 11: Train - Avg loss: 2.0824; Test - Avg loss: 2.1553, Accuracy: 919/5000 (18%)\n",
      "For epoch 12: Train - Avg loss: 2.0311; Test - Avg loss: 2.2377, Accuracy: 946/5000 (19%)\n",
      "For epoch 13: Train - Avg loss: 2.0597; Test - Avg loss: 2.1442, Accuracy: 986/5000 (20%)\n",
      "For epoch 14: Train - Avg loss: 1.9655; Test - Avg loss: 2.1937, Accuracy: 928/5000 (19%)\n",
      "For epoch 15: Train - Avg loss: 2.0044; Test - Avg loss: 2.1622, Accuracy: 1039/5000 (21%)\n",
      "For epoch 16: Train - Avg loss: 1.9957; Test - Avg loss: 2.1285, Accuracy: 1098/5000 (22%)\n",
      "For epoch 17: Train - Avg loss: 1.9338; Test - Avg loss: 2.0408, Accuracy: 1280/5000 (26%)\n",
      "For epoch 18: Train - Avg loss: 1.8669; Test - Avg loss: 2.0400, Accuracy: 1243/5000 (25%)\n",
      "For epoch 19: Train - Avg loss: 1.8622; Test - Avg loss: 2.0811, Accuracy: 1180/5000 (24%)\n",
      "For epoch 20: Train - Avg loss: 1.8371; Test - Avg loss: 2.0072, Accuracy: 1399/5000 (28%)\n",
      "For epoch 21: Train - Avg loss: 1.7810; Test - Avg loss: 1.9862, Accuracy: 1397/5000 (28%)\n",
      "For epoch 22: Train - Avg loss: 1.6961; Test - Avg loss: 1.9989, Accuracy: 1450/5000 (29%)\n",
      "For epoch 23: Train - Avg loss: 1.6870; Test - Avg loss: 2.0208, Accuracy: 1355/5000 (27%)\n",
      "For epoch 24: Train - Avg loss: 1.6520; Test - Avg loss: 2.0081, Accuracy: 1434/5000 (29%)\n",
      "Test loss: 1.9730542072296142; Accuracy 2973/10000\n",
      "Acquiring BALD batch. acq_num: 2 Pool size: 9900\n",
      "Time taken for acquisition score computation: 54.76115274429321\n",
      "For epoch 0: Train - Avg loss: 2.2862; Test - Avg loss: 2.3121, Accuracy: 504/5000 (10%)\n",
      "For epoch 1: Train - Avg loss: 2.3229; Test - Avg loss: 2.3012, Accuracy: 504/5000 (10%)\n",
      "For epoch 2: Train - Avg loss: 2.2996; Test - Avg loss: 2.3039, Accuracy: 471/5000 (9%)\n",
      "For epoch 3: Train - Avg loss: 2.2994; Test - Avg loss: 2.3033, Accuracy: 471/5000 (9%)\n",
      "For epoch 4: Train - Avg loss: 2.2954; Test - Avg loss: 2.3024, Accuracy: 545/5000 (11%)\n",
      "For epoch 5: Train - Avg loss: 2.2916; Test - Avg loss: 2.2993, Accuracy: 707/5000 (14%)\n",
      "For epoch 6: Train - Avg loss: 2.2726; Test - Avg loss: 2.2813, Accuracy: 568/5000 (11%)\n",
      "For epoch 7: Train - Avg loss: 2.2669; Test - Avg loss: 2.2738, Accuracy: 682/5000 (14%)\n",
      "For epoch 8: Train - Avg loss: 2.2274; Test - Avg loss: 2.2522, Accuracy: 565/5000 (11%)\n",
      "For epoch 9: Train - Avg loss: 2.1925; Test - Avg loss: 2.1634, Accuracy: 805/5000 (16%)\n",
      "For epoch 10: Train - Avg loss: 2.1457; Test - Avg loss: 2.2273, Accuracy: 762/5000 (15%)\n",
      "For epoch 11: Train - Avg loss: 2.1321; Test - Avg loss: 2.1003, Accuracy: 1128/5000 (23%)\n",
      "For epoch 12: Train - Avg loss: 2.0826; Test - Avg loss: 2.0889, Accuracy: 1189/5000 (24%)\n",
      "For epoch 13: Train - Avg loss: 2.0804; Test - Avg loss: 2.0787, Accuracy: 1198/5000 (24%)\n",
      "For epoch 14: Train - Avg loss: 2.0255; Test - Avg loss: 2.0931, Accuracy: 1021/5000 (20%)\n",
      "For epoch 15: Train - Avg loss: 2.0179; Test - Avg loss: 2.0756, Accuracy: 1105/5000 (22%)\n",
      "For epoch 16: Train - Avg loss: 1.9454; Test - Avg loss: 2.0956, Accuracy: 1067/5000 (21%)\n",
      "For epoch 17: Train - Avg loss: 1.9957; Test - Avg loss: 2.0438, Accuracy: 1223/5000 (24%)\n",
      "For epoch 18: Train - Avg loss: 1.8966; Test - Avg loss: 2.0623, Accuracy: 1288/5000 (26%)\n",
      "For epoch 19: Train - Avg loss: 1.9009; Test - Avg loss: 2.0537, Accuracy: 1333/5000 (27%)\n",
      "For epoch 20: Train - Avg loss: 1.8674; Test - Avg loss: 2.1239, Accuracy: 1155/5000 (23%)\n",
      "For epoch 21: Train - Avg loss: 1.8240; Test - Avg loss: 1.9749, Accuracy: 1405/5000 (28%)\n",
      "For epoch 22: Train - Avg loss: 1.7934; Test - Avg loss: 1.9995, Accuracy: 1402/5000 (28%)\n",
      "For epoch 23: Train - Avg loss: 1.8243; Test - Avg loss: 1.9463, Accuracy: 1503/5000 (30%)\n",
      "For epoch 24: Train - Avg loss: 1.7251; Test - Avg loss: 2.0299, Accuracy: 1427/5000 (29%)\n",
      "Test loss: 2.009001036071777; Accuracy 2877/10000\n",
      "Acquiring BALD batch. acq_num: 3 Pool size: 9800\n",
      "Time taken for acquisition score computation: 55.114649295806885\n",
      "For epoch 0: Train - Avg loss: 2.3046; Test - Avg loss: 2.3038, Accuracy: 615/5000 (12%)\n",
      "For epoch 1: Train - Avg loss: 2.2995; Test - Avg loss: 2.3051, Accuracy: 512/5000 (10%)\n",
      "For epoch 2: Train - Avg loss: 2.2926; Test - Avg loss: 2.3014, Accuracy: 512/5000 (10%)\n",
      "For epoch 3: Train - Avg loss: 2.2868; Test - Avg loss: 2.2914, Accuracy: 711/5000 (14%)\n",
      "For epoch 4: Train - Avg loss: 2.2769; Test - Avg loss: 2.2726, Accuracy: 909/5000 (18%)\n",
      "For epoch 5: Train - Avg loss: 2.2842; Test - Avg loss: 2.2806, Accuracy: 847/5000 (17%)\n",
      "For epoch 6: Train - Avg loss: 2.2533; Test - Avg loss: 2.2264, Accuracy: 943/5000 (19%)\n",
      "For epoch 7: Train - Avg loss: 2.2141; Test - Avg loss: 2.2116, Accuracy: 939/5000 (19%)\n",
      "For epoch 8: Train - Avg loss: 2.1938; Test - Avg loss: 2.1701, Accuracy: 921/5000 (18%)\n",
      "For epoch 9: Train - Avg loss: 2.1583; Test - Avg loss: 2.1379, Accuracy: 1122/5000 (22%)\n",
      "For epoch 10: Train - Avg loss: 2.1257; Test - Avg loss: 2.0692, Accuracy: 1233/5000 (25%)\n",
      "For epoch 11: Train - Avg loss: 2.1014; Test - Avg loss: 2.1056, Accuracy: 1088/5000 (22%)\n",
      "For epoch 12: Train - Avg loss: 2.0292; Test - Avg loss: 2.0211, Accuracy: 1288/5000 (26%)\n",
      "For epoch 13: Train - Avg loss: 1.9548; Test - Avg loss: 2.0142, Accuracy: 1291/5000 (26%)\n",
      "For epoch 14: Train - Avg loss: 1.9259; Test - Avg loss: 1.9706, Accuracy: 1401/5000 (28%)\n",
      "For epoch 15: Train - Avg loss: 1.8826; Test - Avg loss: 1.9603, Accuracy: 1428/5000 (29%)\n",
      "For epoch 16: Train - Avg loss: 1.8033; Test - Avg loss: 1.9402, Accuracy: 1403/5000 (28%)\n",
      "For epoch 17: Train - Avg loss: 1.7700; Test - Avg loss: 1.9134, Accuracy: 1534/5000 (31%)\n",
      "For epoch 18: Train - Avg loss: 1.6525; Test - Avg loss: 1.8778, Accuracy: 1572/5000 (31%)\n",
      "For epoch 19: Train - Avg loss: 1.6292; Test - Avg loss: 1.8929, Accuracy: 1640/5000 (33%)\n",
      "For epoch 20: Train - Avg loss: 1.6165; Test - Avg loss: 2.0736, Accuracy: 1557/5000 (31%)\n",
      "For epoch 21: Train - Avg loss: 1.6585; Test - Avg loss: 1.8383, Accuracy: 1701/5000 (34%)\n",
      "For epoch 22: Train - Avg loss: 1.5510; Test - Avg loss: 1.8057, Accuracy: 1788/5000 (36%)\n",
      "For epoch 23: Train - Avg loss: 1.4460; Test - Avg loss: 1.8296, Accuracy: 1794/5000 (36%)\n",
      "For epoch 24: Train - Avg loss: 1.3795; Test - Avg loss: 1.9064, Accuracy: 1770/5000 (35%)\n",
      "Test loss: 1.8859283737182617; Accuracy 3634/10000\n",
      "Acquiring BALD batch. acq_num: 4 Pool size: 9700\n",
      "Time taken for acquisition score computation: 52.519065618515015\n",
      "For epoch 0: Train - Avg loss: 2.3025; Test - Avg loss: 2.3024, Accuracy: 488/5000 (10%)\n",
      "For epoch 1: Train - Avg loss: 2.2914; Test - Avg loss: 2.2877, Accuracy: 650/5000 (13%)\n",
      "For epoch 2: Train - Avg loss: 2.2749; Test - Avg loss: 2.2439, Accuracy: 629/5000 (13%)\n",
      "For epoch 3: Train - Avg loss: 2.2383; Test - Avg loss: 2.2133, Accuracy: 899/5000 (18%)\n",
      "For epoch 4: Train - Avg loss: 2.2118; Test - Avg loss: 2.1767, Accuracy: 947/5000 (19%)\n",
      "For epoch 5: Train - Avg loss: 2.2093; Test - Avg loss: 2.1593, Accuracy: 952/5000 (19%)\n",
      "For epoch 6: Train - Avg loss: 2.1656; Test - Avg loss: 2.1196, Accuracy: 1011/5000 (20%)\n",
      "For epoch 7: Train - Avg loss: 2.1167; Test - Avg loss: 2.0770, Accuracy: 1137/5000 (23%)\n",
      "For epoch 8: Train - Avg loss: 2.1463; Test - Avg loss: 2.0794, Accuracy: 1183/5000 (24%)\n",
      "For epoch 9: Train - Avg loss: 2.1065; Test - Avg loss: 2.0822, Accuracy: 1201/5000 (24%)\n",
      "For epoch 10: Train - Avg loss: 2.0822; Test - Avg loss: 2.0702, Accuracy: 1163/5000 (23%)\n",
      "For epoch 11: Train - Avg loss: 2.0603; Test - Avg loss: 2.0526, Accuracy: 1217/5000 (24%)\n",
      "For epoch 12: Train - Avg loss: 2.0359; Test - Avg loss: 2.0214, Accuracy: 1272/5000 (25%)\n",
      "For epoch 13: Train - Avg loss: 2.0242; Test - Avg loss: 1.9882, Accuracy: 1303/5000 (26%)\n",
      "For epoch 14: Train - Avg loss: 1.9369; Test - Avg loss: 1.9299, Accuracy: 1474/5000 (29%)\n",
      "For epoch 15: Train - Avg loss: 1.8591; Test - Avg loss: 1.8607, Accuracy: 1493/5000 (30%)\n",
      "For epoch 16: Train - Avg loss: 1.8951; Test - Avg loss: 1.8796, Accuracy: 1476/5000 (30%)\n",
      "For epoch 17: Train - Avg loss: 1.7976; Test - Avg loss: 1.9444, Accuracy: 1506/5000 (30%)\n",
      "For epoch 18: Train - Avg loss: 1.8022; Test - Avg loss: 1.9863, Accuracy: 1313/5000 (26%)\n",
      "For epoch 19: Train - Avg loss: 1.7712; Test - Avg loss: 1.8229, Accuracy: 1527/5000 (31%)\n",
      "For epoch 20: Train - Avg loss: 1.6582; Test - Avg loss: 1.8075, Accuracy: 1650/5000 (33%)\n",
      "For epoch 21: Train - Avg loss: 1.6265; Test - Avg loss: 1.8678, Accuracy: 1790/5000 (36%)\n",
      "For epoch 22: Train - Avg loss: 1.5379; Test - Avg loss: 1.7935, Accuracy: 1793/5000 (36%)\n",
      "For epoch 23: Train - Avg loss: 1.4824; Test - Avg loss: 1.8809, Accuracy: 1748/5000 (35%)\n",
      "For epoch 24: Train - Avg loss: 1.4518; Test - Avg loss: 1.8161, Accuracy: 1793/5000 (36%)\n",
      "Test loss: 1.7887741136550903; Accuracy 3727/10000\n",
      "Acquiring BALD batch. acq_num: 5 Pool size: 9600\n",
      "Time taken for acquisition score computation: 49.98828721046448\n",
      "For epoch 0: Train - Avg loss: 2.3050; Test - Avg loss: 2.3019, Accuracy: 488/5000 (10%)\n",
      "For epoch 1: Train - Avg loss: 2.2999; Test - Avg loss: 2.3005, Accuracy: 488/5000 (10%)\n",
      "For epoch 2: Train - Avg loss: 2.2956; Test - Avg loss: 2.2773, Accuracy: 488/5000 (10%)\n",
      "For epoch 3: Train - Avg loss: 2.2717; Test - Avg loss: 2.2477, Accuracy: 488/5000 (10%)\n",
      "For epoch 4: Train - Avg loss: 2.2486; Test - Avg loss: 2.2101, Accuracy: 838/5000 (17%)\n",
      "For epoch 5: Train - Avg loss: 2.2153; Test - Avg loss: 2.1849, Accuracy: 958/5000 (19%)\n",
      "For epoch 6: Train - Avg loss: 2.2055; Test - Avg loss: 2.1536, Accuracy: 981/5000 (20%)\n",
      "For epoch 7: Train - Avg loss: 2.1687; Test - Avg loss: 2.0967, Accuracy: 1095/5000 (22%)\n",
      "For epoch 8: Train - Avg loss: 2.1301; Test - Avg loss: 2.0636, Accuracy: 1221/5000 (24%)\n",
      "For epoch 9: Train - Avg loss: 2.0984; Test - Avg loss: 2.0425, Accuracy: 1214/5000 (24%)\n",
      "For epoch 10: Train - Avg loss: 2.0823; Test - Avg loss: 2.0634, Accuracy: 1150/5000 (23%)\n",
      "For epoch 11: Train - Avg loss: 2.0940; Test - Avg loss: 1.9945, Accuracy: 1306/5000 (26%)\n",
      "For epoch 12: Train - Avg loss: 2.0413; Test - Avg loss: 1.9730, Accuracy: 1342/5000 (27%)\n",
      "For epoch 13: Train - Avg loss: 1.9869; Test - Avg loss: 1.9755, Accuracy: 1397/5000 (28%)\n",
      "For epoch 14: Train - Avg loss: 1.9621; Test - Avg loss: 1.8904, Accuracy: 1541/5000 (31%)\n",
      "For epoch 15: Train - Avg loss: 1.8655; Test - Avg loss: 1.9719, Accuracy: 1432/5000 (29%)\n",
      "For epoch 16: Train - Avg loss: 1.8712; Test - Avg loss: 1.9108, Accuracy: 1585/5000 (32%)\n",
      "For epoch 17: Train - Avg loss: 1.8146; Test - Avg loss: 1.8637, Accuracy: 1636/5000 (33%)\n",
      "For epoch 18: Train - Avg loss: 1.7765; Test - Avg loss: 1.8486, Accuracy: 1668/5000 (33%)\n",
      "For epoch 19: Train - Avg loss: 1.7135; Test - Avg loss: 1.8095, Accuracy: 1739/5000 (35%)\n",
      "For epoch 20: Train - Avg loss: 1.5837; Test - Avg loss: 2.0024, Accuracy: 1775/5000 (36%)\n",
      "For epoch 21: Train - Avg loss: 1.6013; Test - Avg loss: 1.7682, Accuracy: 1903/5000 (38%)\n",
      "For epoch 22: Train - Avg loss: 1.5199; Test - Avg loss: 1.8880, Accuracy: 1880/5000 (38%)\n",
      "For epoch 23: Train - Avg loss: 1.4009; Test - Avg loss: 1.9614, Accuracy: 1874/5000 (37%)\n",
      "For epoch 24: Train - Avg loss: 1.3515; Test - Avg loss: 1.7530, Accuracy: 2020/5000 (40%)\n",
      "Test loss: 1.7422721157073975; Accuracy 4026/10000\n",
      "Acquiring BALD batch. acq_num: 6 Pool size: 9500\n",
      "Time taken for acquisition score computation: 53.40300273895264\n",
      "For epoch 0: Train - Avg loss: 2.3052; Test - Avg loss: 2.3015, Accuracy: 512/5000 (10%)\n",
      "For epoch 1: Train - Avg loss: 2.2982; Test - Avg loss: 2.2983, Accuracy: 521/5000 (10%)\n",
      "For epoch 2: Train - Avg loss: 2.2926; Test - Avg loss: 2.2786, Accuracy: 580/5000 (12%)\n",
      "For epoch 3: Train - Avg loss: 2.2810; Test - Avg loss: 2.2689, Accuracy: 666/5000 (13%)\n",
      "For epoch 4: Train - Avg loss: 2.2701; Test - Avg loss: 2.2414, Accuracy: 891/5000 (18%)\n",
      "For epoch 5: Train - Avg loss: 2.2472; Test - Avg loss: 2.1756, Accuracy: 875/5000 (18%)\n",
      "For epoch 6: Train - Avg loss: 2.1963; Test - Avg loss: 2.1367, Accuracy: 964/5000 (19%)\n",
      "For epoch 7: Train - Avg loss: 2.1806; Test - Avg loss: 2.1084, Accuracy: 1073/5000 (21%)\n",
      "For epoch 8: Train - Avg loss: 2.1604; Test - Avg loss: 2.0595, Accuracy: 1222/5000 (24%)\n",
      "For epoch 9: Train - Avg loss: 2.1379; Test - Avg loss: 2.0690, Accuracy: 1148/5000 (23%)\n",
      "For epoch 10: Train - Avg loss: 2.0905; Test - Avg loss: 2.0312, Accuracy: 1239/5000 (25%)\n",
      "For epoch 11: Train - Avg loss: 2.1148; Test - Avg loss: 2.0227, Accuracy: 1335/5000 (27%)\n",
      "For epoch 12: Train - Avg loss: 2.0603; Test - Avg loss: 1.9393, Accuracy: 1412/5000 (28%)\n",
      "For epoch 13: Train - Avg loss: 2.0322; Test - Avg loss: 1.9612, Accuracy: 1370/5000 (27%)\n",
      "For epoch 14: Train - Avg loss: 1.9996; Test - Avg loss: 1.8898, Accuracy: 1404/5000 (28%)\n",
      "For epoch 15: Train - Avg loss: 2.0124; Test - Avg loss: 1.8642, Accuracy: 1573/5000 (31%)\n",
      "For epoch 16: Train - Avg loss: 1.8889; Test - Avg loss: 1.8953, Accuracy: 1486/5000 (30%)\n",
      "For epoch 17: Train - Avg loss: 1.8206; Test - Avg loss: 1.8615, Accuracy: 1593/5000 (32%)\n",
      "For epoch 18: Train - Avg loss: 1.7381; Test - Avg loss: 1.8389, Accuracy: 1700/5000 (34%)\n",
      "For epoch 19: Train - Avg loss: 1.7433; Test - Avg loss: 1.8674, Accuracy: 1622/5000 (32%)\n",
      "For epoch 20: Train - Avg loss: 1.6639; Test - Avg loss: 1.7647, Accuracy: 1865/5000 (37%)\n",
      "For epoch 21: Train - Avg loss: 1.5768; Test - Avg loss: 1.8204, Accuracy: 1751/5000 (35%)\n",
      "For epoch 22: Train - Avg loss: 1.4839; Test - Avg loss: 1.8117, Accuracy: 1948/5000 (39%)\n",
      "For epoch 23: Train - Avg loss: 1.4040; Test - Avg loss: 1.7584, Accuracy: 1965/5000 (39%)\n",
      "For epoch 24: Train - Avg loss: 1.3559; Test - Avg loss: 1.7425, Accuracy: 1981/5000 (40%)\n",
      "Test loss: 1.7047696901321412; Accuracy 3992/10000\n",
      "Acquiring BALD batch. acq_num: 7 Pool size: 9400\n",
      "Time taken for acquisition score computation: 52.04837608337402\n",
      "For epoch 0: Train - Avg loss: 2.3029; Test - Avg loss: 2.3035, Accuracy: 512/5000 (10%)\n",
      "For epoch 1: Train - Avg loss: 2.3022; Test - Avg loss: 2.3049, Accuracy: 512/5000 (10%)\n",
      "For epoch 2: Train - Avg loss: 2.3013; Test - Avg loss: 2.3042, Accuracy: 507/5000 (10%)\n",
      "For epoch 3: Train - Avg loss: 2.3010; Test - Avg loss: 2.3049, Accuracy: 507/5000 (10%)\n",
      "For epoch 4: Train - Avg loss: 2.3040; Test - Avg loss: 2.3043, Accuracy: 507/5000 (10%)\n",
      "For epoch 5: Train - Avg loss: 2.2950; Test - Avg loss: 2.3043, Accuracy: 507/5000 (10%)\n",
      "For epoch 6: Train - Avg loss: 2.2959; Test - Avg loss: 2.3055, Accuracy: 510/5000 (10%)\n",
      "For epoch 7: Train - Avg loss: 2.2994; Test - Avg loss: 2.3033, Accuracy: 744/5000 (15%)\n",
      "For epoch 8: Train - Avg loss: 2.2969; Test - Avg loss: 2.2951, Accuracy: 512/5000 (10%)\n",
      "For epoch 9: Train - Avg loss: 2.3041; Test - Avg loss: 2.2928, Accuracy: 588/5000 (12%)\n",
      "For epoch 10: Train - Avg loss: 2.2917; Test - Avg loss: 2.2623, Accuracy: 826/5000 (17%)\n",
      "For epoch 11: Train - Avg loss: 2.2823; Test - Avg loss: 2.2154, Accuracy: 809/5000 (16%)\n",
      "For epoch 12: Train - Avg loss: 2.3102; Test - Avg loss: 2.3006, Accuracy: 489/5000 (10%)\n",
      "For epoch 13: Train - Avg loss: 2.2969; Test - Avg loss: 2.2954, Accuracy: 600/5000 (12%)\n",
      "For epoch 14: Train - Avg loss: 2.2777; Test - Avg loss: 2.2686, Accuracy: 753/5000 (15%)\n",
      "For epoch 15: Train - Avg loss: 2.2743; Test - Avg loss: 2.2176, Accuracy: 979/5000 (20%)\n",
      "For epoch 16: Train - Avg loss: 2.2441; Test - Avg loss: 2.2340, Accuracy: 834/5000 (17%)\n",
      "For epoch 17: Train - Avg loss: 2.2361; Test - Avg loss: 2.1827, Accuracy: 997/5000 (20%)\n",
      "For epoch 18: Train - Avg loss: 2.2271; Test - Avg loss: 2.1859, Accuracy: 1041/5000 (21%)\n",
      "For epoch 19: Train - Avg loss: 2.1842; Test - Avg loss: 2.1483, Accuracy: 1011/5000 (20%)\n",
      "For epoch 20: Train - Avg loss: 2.1667; Test - Avg loss: 2.1615, Accuracy: 1046/5000 (21%)\n",
      "For epoch 21: Train - Avg loss: 2.1857; Test - Avg loss: 2.0751, Accuracy: 1199/5000 (24%)\n",
      "For epoch 22: Train - Avg loss: 2.1563; Test - Avg loss: 2.0925, Accuracy: 1195/5000 (24%)\n",
      "For epoch 23: Train - Avg loss: 2.1351; Test - Avg loss: 2.0813, Accuracy: 1220/5000 (24%)\n",
      "For epoch 24: Train - Avg loss: 2.1562; Test - Avg loss: 2.1393, Accuracy: 1253/5000 (25%)\n",
      "Test loss: 2.12185560798645; Accuracy 2612/10000\n",
      "Acquiring BALD batch. acq_num: 8 Pool size: 9300\n",
      "Time taken for acquisition score computation: 50.973077058792114\n",
      "For epoch 0: Train - Avg loss: 2.3052; Test - Avg loss: 2.3032, Accuracy: 471/5000 (9%)\n",
      "For epoch 1: Train - Avg loss: 2.3019; Test - Avg loss: 2.3064, Accuracy: 471/5000 (9%)\n",
      "For epoch 2: Train - Avg loss: 2.2964; Test - Avg loss: 2.3046, Accuracy: 524/5000 (10%)\n",
      "For epoch 3: Train - Avg loss: 2.2966; Test - Avg loss: 2.3076, Accuracy: 506/5000 (10%)\n",
      "For epoch 4: Train - Avg loss: 2.2905; Test - Avg loss: 2.2934, Accuracy: 783/5000 (16%)\n",
      "For epoch 5: Train - Avg loss: 2.2735; Test - Avg loss: 2.2195, Accuracy: 896/5000 (18%)\n",
      "For epoch 6: Train - Avg loss: 2.2388; Test - Avg loss: 2.1830, Accuracy: 1037/5000 (21%)\n",
      "For epoch 7: Train - Avg loss: 2.2381; Test - Avg loss: 2.1257, Accuracy: 1133/5000 (23%)\n",
      "For epoch 8: Train - Avg loss: 2.1664; Test - Avg loss: 2.0342, Accuracy: 1209/5000 (24%)\n",
      "For epoch 9: Train - Avg loss: 2.1431; Test - Avg loss: 1.9841, Accuracy: 1385/5000 (28%)\n",
      "For epoch 10: Train - Avg loss: 2.0823; Test - Avg loss: 1.9407, Accuracy: 1375/5000 (28%)\n",
      "For epoch 11: Train - Avg loss: 2.0218; Test - Avg loss: 1.9218, Accuracy: 1345/5000 (27%)\n",
      "For epoch 12: Train - Avg loss: 1.9723; Test - Avg loss: 1.8185, Accuracy: 1628/5000 (33%)\n",
      "For epoch 13: Train - Avg loss: 1.9515; Test - Avg loss: 1.7991, Accuracy: 1777/5000 (36%)\n",
      "For epoch 14: Train - Avg loss: 1.8596; Test - Avg loss: 1.7810, Accuracy: 1669/5000 (33%)\n",
      "For epoch 15: Train - Avg loss: 1.8008; Test - Avg loss: 1.7488, Accuracy: 1844/5000 (37%)\n",
      "For epoch 16: Train - Avg loss: 1.7287; Test - Avg loss: 1.7251, Accuracy: 1865/5000 (37%)\n",
      "For epoch 17: Train - Avg loss: 1.6328; Test - Avg loss: 1.7299, Accuracy: 1880/5000 (38%)\n",
      "For epoch 18: Train - Avg loss: 1.6081; Test - Avg loss: 1.6547, Accuracy: 2050/5000 (41%)\n",
      "For epoch 19: Train - Avg loss: 1.5198; Test - Avg loss: 1.6853, Accuracy: 2016/5000 (40%)\n",
      "For epoch 20: Train - Avg loss: 1.4797; Test - Avg loss: 1.7146, Accuracy: 2010/5000 (40%)\n",
      "For epoch 21: Train - Avg loss: 1.3719; Test - Avg loss: 1.7016, Accuracy: 2182/5000 (44%)\n",
      "For epoch 22: Train - Avg loss: 1.3233; Test - Avg loss: 1.7039, Accuracy: 2151/5000 (43%)\n",
      "For epoch 23: Train - Avg loss: 1.2206; Test - Avg loss: 1.7031, Accuracy: 2198/5000 (44%)\n",
      "For epoch 24: Train - Avg loss: 1.1122; Test - Avg loss: 1.8884, Accuracy: 2120/5000 (42%)\n",
      "Test loss: 1.863821280670166; Accuracy 4257/10000\n",
      "Acquiring BALD batch. acq_num: 9 Pool size: 9200\n",
      "Time taken for acquisition score computation: 50.16071891784668\n",
      "For epoch 0: Train - Avg loss: 2.3069; Test - Avg loss: 2.3032, Accuracy: 488/5000 (10%)\n",
      "For epoch 1: Train - Avg loss: 2.3035; Test - Avg loss: 2.3021, Accuracy: 658/5000 (13%)\n",
      "For epoch 2: Train - Avg loss: 2.3035; Test - Avg loss: 2.3002, Accuracy: 509/5000 (10%)\n",
      "For epoch 3: Train - Avg loss: 2.3000; Test - Avg loss: 2.2995, Accuracy: 502/5000 (10%)\n",
      "For epoch 4: Train - Avg loss: 2.2967; Test - Avg loss: 2.2898, Accuracy: 594/5000 (12%)\n",
      "For epoch 5: Train - Avg loss: 2.2848; Test - Avg loss: 2.2845, Accuracy: 701/5000 (14%)\n",
      "For epoch 6: Train - Avg loss: 2.2763; Test - Avg loss: 2.2380, Accuracy: 918/5000 (18%)\n",
      "For epoch 7: Train - Avg loss: 2.2484; Test - Avg loss: 2.1971, Accuracy: 931/5000 (19%)\n",
      "For epoch 8: Train - Avg loss: 2.2048; Test - Avg loss: 2.0943, Accuracy: 1155/5000 (23%)\n",
      "For epoch 9: Train - Avg loss: 2.1865; Test - Avg loss: 2.0444, Accuracy: 1234/5000 (25%)\n",
      "For epoch 10: Train - Avg loss: 2.1320; Test - Avg loss: 2.0146, Accuracy: 1228/5000 (25%)\n",
      "For epoch 11: Train - Avg loss: 2.1119; Test - Avg loss: 1.9911, Accuracy: 1373/5000 (27%)\n",
      "For epoch 12: Train - Avg loss: 2.0690; Test - Avg loss: 1.9214, Accuracy: 1458/5000 (29%)\n",
      "For epoch 13: Train - Avg loss: 1.9955; Test - Avg loss: 1.8394, Accuracy: 1546/5000 (31%)\n",
      "For epoch 14: Train - Avg loss: 1.9530; Test - Avg loss: 1.8554, Accuracy: 1559/5000 (31%)\n",
      "For epoch 15: Train - Avg loss: 1.8788; Test - Avg loss: 1.8168, Accuracy: 1614/5000 (32%)\n",
      "For epoch 16: Train - Avg loss: 1.8818; Test - Avg loss: 1.7839, Accuracy: 1707/5000 (34%)\n",
      "For epoch 17: Train - Avg loss: 1.7594; Test - Avg loss: 1.7983, Accuracy: 1661/5000 (33%)\n",
      "For epoch 18: Train - Avg loss: 1.7150; Test - Avg loss: 1.7597, Accuracy: 1807/5000 (36%)\n",
      "For epoch 19: Train - Avg loss: 1.6146; Test - Avg loss: 1.7939, Accuracy: 1735/5000 (35%)\n",
      "For epoch 20: Train - Avg loss: 1.5693; Test - Avg loss: 1.7086, Accuracy: 1884/5000 (38%)\n",
      "For epoch 21: Train - Avg loss: 1.4115; Test - Avg loss: 1.7693, Accuracy: 1934/5000 (39%)\n",
      "For epoch 22: Train - Avg loss: 1.3187; Test - Avg loss: 1.6978, Accuracy: 2066/5000 (41%)\n",
      "For epoch 23: Train - Avg loss: 1.2413; Test - Avg loss: 1.8242, Accuracy: 2006/5000 (40%)\n",
      "For epoch 24: Train - Avg loss: 1.1718; Test - Avg loss: 1.8741, Accuracy: 1999/5000 (40%)\n",
      "Test loss: 1.840669501876831; Accuracy 3955/10000\n",
      "Acquiring BALD batch. acq_num: 10 Pool size: 9100\n",
      "Time taken for acquisition score computation: 49.722498178482056\n",
      "For epoch 0: Train - Avg loss: 2.3045; Test - Avg loss: 2.3027, Accuracy: 471/5000 (9%)\n",
      "For epoch 1: Train - Avg loss: 2.3018; Test - Avg loss: 2.3012, Accuracy: 512/5000 (10%)\n",
      "For epoch 2: Train - Avg loss: 2.2951; Test - Avg loss: 2.2876, Accuracy: 512/5000 (10%)\n",
      "For epoch 3: Train - Avg loss: 2.2796; Test - Avg loss: 2.2615, Accuracy: 784/5000 (16%)\n",
      "For epoch 4: Train - Avg loss: 2.2566; Test - Avg loss: 2.1935, Accuracy: 807/5000 (16%)\n",
      "For epoch 5: Train - Avg loss: 2.2137; Test - Avg loss: 2.1056, Accuracy: 1120/5000 (22%)\n",
      "For epoch 6: Train - Avg loss: 2.2074; Test - Avg loss: 2.1720, Accuracy: 1125/5000 (22%)\n",
      "For epoch 7: Train - Avg loss: 2.1830; Test - Avg loss: 2.0322, Accuracy: 1398/5000 (28%)\n",
      "For epoch 8: Train - Avg loss: 2.0754; Test - Avg loss: 1.9192, Accuracy: 1560/5000 (31%)\n",
      "For epoch 9: Train - Avg loss: 2.0817; Test - Avg loss: 1.9595, Accuracy: 1448/5000 (29%)\n",
      "For epoch 10: Train - Avg loss: 2.0057; Test - Avg loss: 1.8774, Accuracy: 1649/5000 (33%)\n",
      "For epoch 11: Train - Avg loss: 1.9456; Test - Avg loss: 1.7996, Accuracy: 1696/5000 (34%)\n",
      "For epoch 12: Train - Avg loss: 1.8736; Test - Avg loss: 1.8331, Accuracy: 1610/5000 (32%)\n",
      "For epoch 13: Train - Avg loss: 1.8199; Test - Avg loss: 1.7354, Accuracy: 1790/5000 (36%)\n",
      "For epoch 14: Train - Avg loss: 1.7391; Test - Avg loss: 1.6898, Accuracy: 1935/5000 (39%)\n",
      "For epoch 15: Train - Avg loss: 1.6072; Test - Avg loss: 1.7157, Accuracy: 1902/5000 (38%)\n",
      "For epoch 16: Train - Avg loss: 1.5489; Test - Avg loss: 1.7039, Accuracy: 1937/5000 (39%)\n",
      "For epoch 17: Train - Avg loss: 1.4826; Test - Avg loss: 1.6584, Accuracy: 2041/5000 (41%)\n",
      "For epoch 18: Train - Avg loss: 1.3030; Test - Avg loss: 1.7240, Accuracy: 2070/5000 (41%)\n",
      "For epoch 19: Train - Avg loss: 1.3017; Test - Avg loss: 1.7611, Accuracy: 2007/5000 (40%)\n",
      "For epoch 20: Train - Avg loss: 1.1379; Test - Avg loss: 1.7575, Accuracy: 2151/5000 (43%)\n",
      "For epoch 21: Train - Avg loss: 1.0658; Test - Avg loss: 1.7455, Accuracy: 2082/5000 (42%)\n",
      "For epoch 22: Train - Avg loss: 0.9719; Test - Avg loss: 1.8676, Accuracy: 2181/5000 (44%)\n",
      "For epoch 23: Train - Avg loss: 0.8671; Test - Avg loss: 1.9110, Accuracy: 2183/5000 (44%)\n",
      "For epoch 24: Train - Avg loss: 0.8182; Test - Avg loss: 1.9125, Accuracy: 2178/5000 (44%)\n",
      "Test loss: 1.9410396427154541; Accuracy 4263/10000\n",
      "Acquiring BALD batch. acq_num: 11 Pool size: 9000\n",
      "Time taken for acquisition score computation: 49.94122242927551\n",
      "For epoch 0: Train - Avg loss: 2.3046; Test - Avg loss: 2.3020, Accuracy: 512/5000 (10%)\n",
      "For epoch 1: Train - Avg loss: 2.3004; Test - Avg loss: 2.2971, Accuracy: 512/5000 (10%)\n",
      "For epoch 2: Train - Avg loss: 2.2982; Test - Avg loss: 2.2890, Accuracy: 512/5000 (10%)\n",
      "For epoch 3: Train - Avg loss: 2.2836; Test - Avg loss: 2.2669, Accuracy: 684/5000 (14%)\n",
      "For epoch 4: Train - Avg loss: 2.2589; Test - Avg loss: 2.2068, Accuracy: 1037/5000 (21%)\n",
      "For epoch 5: Train - Avg loss: 2.2521; Test - Avg loss: 2.2202, Accuracy: 945/5000 (19%)\n",
      "For epoch 6: Train - Avg loss: 2.2270; Test - Avg loss: 2.1147, Accuracy: 1204/5000 (24%)\n",
      "For epoch 7: Train - Avg loss: 2.1664; Test - Avg loss: 2.0126, Accuracy: 1327/5000 (27%)\n",
      "For epoch 8: Train - Avg loss: 2.0994; Test - Avg loss: 1.9539, Accuracy: 1455/5000 (29%)\n",
      "For epoch 9: Train - Avg loss: 2.0627; Test - Avg loss: 1.8494, Accuracy: 1534/5000 (31%)\n",
      "For epoch 10: Train - Avg loss: 2.0056; Test - Avg loss: 1.8119, Accuracy: 1597/5000 (32%)\n",
      "For epoch 11: Train - Avg loss: 1.9220; Test - Avg loss: 1.7715, Accuracy: 1719/5000 (34%)\n",
      "For epoch 12: Train - Avg loss: 1.8682; Test - Avg loss: 1.6982, Accuracy: 1823/5000 (36%)\n",
      "For epoch 13: Train - Avg loss: 1.8178; Test - Avg loss: 1.7757, Accuracy: 1666/5000 (33%)\n",
      "For epoch 14: Train - Avg loss: 1.8119; Test - Avg loss: 1.6397, Accuracy: 1876/5000 (38%)\n",
      "For epoch 15: Train - Avg loss: 1.6968; Test - Avg loss: 1.6227, Accuracy: 1945/5000 (39%)\n",
      "For epoch 16: Train - Avg loss: 1.5964; Test - Avg loss: 1.6308, Accuracy: 1935/5000 (39%)\n",
      "For epoch 17: Train - Avg loss: 1.5624; Test - Avg loss: 1.5792, Accuracy: 1998/5000 (40%)\n",
      "For epoch 18: Train - Avg loss: 1.5023; Test - Avg loss: 1.6160, Accuracy: 1973/5000 (39%)\n",
      "For epoch 19: Train - Avg loss: 1.3974; Test - Avg loss: 1.5876, Accuracy: 2128/5000 (43%)\n",
      "For epoch 20: Train - Avg loss: 1.2970; Test - Avg loss: 1.6149, Accuracy: 2112/5000 (42%)\n",
      "For epoch 21: Train - Avg loss: 1.2054; Test - Avg loss: 1.6416, Accuracy: 2097/5000 (42%)\n",
      "For epoch 22: Train - Avg loss: 1.1380; Test - Avg loss: 1.6596, Accuracy: 2152/5000 (43%)\n",
      "For epoch 23: Train - Avg loss: 1.0361; Test - Avg loss: 1.6510, Accuracy: 2219/5000 (44%)\n",
      "For epoch 24: Train - Avg loss: 0.9801; Test - Avg loss: 1.6612, Accuracy: 2212/5000 (44%)\n",
      "Test loss: 1.680925144958496; Accuracy 4336/10000\n",
      "Acquiring BALD batch. acq_num: 12 Pool size: 8900\n",
      "Time taken for acquisition score computation: 47.19493126869202\n",
      "For epoch 0: Train - Avg loss: 2.3039; Test - Avg loss: 2.3011, Accuracy: 512/5000 (10%)\n",
      "For epoch 1: Train - Avg loss: 2.2886; Test - Avg loss: 2.2833, Accuracy: 501/5000 (10%)\n",
      "For epoch 2: Train - Avg loss: 2.2818; Test - Avg loss: 2.2670, Accuracy: 708/5000 (14%)\n",
      "For epoch 3: Train - Avg loss: 2.2570; Test - Avg loss: 2.1412, Accuracy: 993/5000 (20%)\n",
      "For epoch 4: Train - Avg loss: 2.2162; Test - Avg loss: 2.1031, Accuracy: 1226/5000 (25%)\n",
      "For epoch 5: Train - Avg loss: 2.1761; Test - Avg loss: 1.9837, Accuracy: 1392/5000 (28%)\n",
      "For epoch 6: Train - Avg loss: 2.1320; Test - Avg loss: 1.9575, Accuracy: 1509/5000 (30%)\n",
      "For epoch 7: Train - Avg loss: 2.0940; Test - Avg loss: 1.8827, Accuracy: 1547/5000 (31%)\n",
      "For epoch 8: Train - Avg loss: 2.0515; Test - Avg loss: 1.8237, Accuracy: 1555/5000 (31%)\n",
      "For epoch 9: Train - Avg loss: 1.9892; Test - Avg loss: 1.8063, Accuracy: 1622/5000 (32%)\n",
      "For epoch 10: Train - Avg loss: 1.9239; Test - Avg loss: 1.7213, Accuracy: 1734/5000 (35%)\n",
      "For epoch 11: Train - Avg loss: 1.8663; Test - Avg loss: 1.7608, Accuracy: 1747/5000 (35%)\n",
      "For epoch 12: Train - Avg loss: 1.8220; Test - Avg loss: 1.6704, Accuracy: 1803/5000 (36%)\n",
      "For epoch 13: Train - Avg loss: 1.7106; Test - Avg loss: 1.6348, Accuracy: 1970/5000 (39%)\n",
      "For epoch 14: Train - Avg loss: 1.6833; Test - Avg loss: 1.6176, Accuracy: 2010/5000 (40%)\n",
      "For epoch 15: Train - Avg loss: 1.5173; Test - Avg loss: 1.6264, Accuracy: 1992/5000 (40%)\n",
      "For epoch 16: Train - Avg loss: 1.4824; Test - Avg loss: 1.6092, Accuracy: 2050/5000 (41%)\n",
      "For epoch 17: Train - Avg loss: 1.3507; Test - Avg loss: 1.6177, Accuracy: 2092/5000 (42%)\n",
      "For epoch 18: Train - Avg loss: 1.2840; Test - Avg loss: 1.6715, Accuracy: 2107/5000 (42%)\n",
      "For epoch 19: Train - Avg loss: 1.1963; Test - Avg loss: 1.6375, Accuracy: 2180/5000 (44%)\n",
      "For epoch 20: Train - Avg loss: 1.0679; Test - Avg loss: 1.7050, Accuracy: 2170/5000 (43%)\n",
      "For epoch 21: Train - Avg loss: 1.0191; Test - Avg loss: 1.6674, Accuracy: 2205/5000 (44%)\n",
      "For epoch 22: Train - Avg loss: 0.9010; Test - Avg loss: 1.8991, Accuracy: 2093/5000 (42%)\n",
      "For epoch 23: Train - Avg loss: 0.7902; Test - Avg loss: 1.9544, Accuracy: 2210/5000 (44%)\n",
      "For epoch 24: Train - Avg loss: 0.6937; Test - Avg loss: 1.8870, Accuracy: 2212/5000 (44%)\n",
      "Test loss: 1.9543650058746338; Accuracy 4380/10000\n",
      "Acquiring BALD batch. acq_num: 13 Pool size: 8800\n",
      "Time taken for acquisition score computation: 48.53393077850342\n",
      "For epoch 0: Train - Avg loss: 2.3045; Test - Avg loss: 2.3027, Accuracy: 512/5000 (10%)\n",
      "For epoch 1: Train - Avg loss: 2.2997; Test - Avg loss: 2.2962, Accuracy: 625/5000 (12%)\n",
      "For epoch 2: Train - Avg loss: 2.2970; Test - Avg loss: 2.2903, Accuracy: 488/5000 (10%)\n",
      "For epoch 3: Train - Avg loss: 2.2939; Test - Avg loss: 2.2617, Accuracy: 674/5000 (13%)\n",
      "For epoch 4: Train - Avg loss: 2.2741; Test - Avg loss: 2.1922, Accuracy: 953/5000 (19%)\n",
      "For epoch 5: Train - Avg loss: 2.2319; Test - Avg loss: 2.0875, Accuracy: 1214/5000 (24%)\n",
      "For epoch 6: Train - Avg loss: 2.1682; Test - Avg loss: 2.0119, Accuracy: 1260/5000 (25%)\n",
      "For epoch 7: Train - Avg loss: 2.1421; Test - Avg loss: 1.9804, Accuracy: 1306/5000 (26%)\n",
      "For epoch 8: Train - Avg loss: 2.1254; Test - Avg loss: 1.9364, Accuracy: 1373/5000 (27%)\n",
      "For epoch 9: Train - Avg loss: 2.0789; Test - Avg loss: 1.8667, Accuracy: 1523/5000 (30%)\n",
      "For epoch 10: Train - Avg loss: 2.0154; Test - Avg loss: 1.8277, Accuracy: 1600/5000 (32%)\n",
      "For epoch 11: Train - Avg loss: 1.9736; Test - Avg loss: 1.7757, Accuracy: 1631/5000 (33%)\n",
      "For epoch 12: Train - Avg loss: 1.9091; Test - Avg loss: 1.7290, Accuracy: 1797/5000 (36%)\n",
      "For epoch 13: Train - Avg loss: 1.8631; Test - Avg loss: 1.7132, Accuracy: 1746/5000 (35%)\n",
      "For epoch 14: Train - Avg loss: 1.7552; Test - Avg loss: 1.6570, Accuracy: 1896/5000 (38%)\n",
      "For epoch 15: Train - Avg loss: 1.6994; Test - Avg loss: 1.6154, Accuracy: 1966/5000 (39%)\n",
      "For epoch 16: Train - Avg loss: 1.5906; Test - Avg loss: 1.5897, Accuracy: 2077/5000 (42%)\n",
      "For epoch 17: Train - Avg loss: 1.4959; Test - Avg loss: 1.5851, Accuracy: 2106/5000 (42%)\n",
      "For epoch 18: Train - Avg loss: 1.3931; Test - Avg loss: 1.5698, Accuracy: 2105/5000 (42%)\n",
      "For epoch 19: Train - Avg loss: 1.2837; Test - Avg loss: 1.5673, Accuracy: 2235/5000 (45%)\n",
      "For epoch 20: Train - Avg loss: 1.1456; Test - Avg loss: 1.6284, Accuracy: 2166/5000 (43%)\n",
      "For epoch 21: Train - Avg loss: 1.0498; Test - Avg loss: 1.5740, Accuracy: 2278/5000 (46%)\n",
      "For epoch 22: Train - Avg loss: 0.9537; Test - Avg loss: 1.6072, Accuracy: 2265/5000 (45%)\n",
      "For epoch 23: Train - Avg loss: 0.8650; Test - Avg loss: 1.7125, Accuracy: 2247/5000 (45%)\n",
      "For epoch 24: Train - Avg loss: 0.7190; Test - Avg loss: 1.8573, Accuracy: 2296/5000 (46%)\n",
      "Test loss: 1.8465084671020509; Accuracy 4592/10000\n",
      "Acquiring BALD batch. acq_num: 14 Pool size: 8700\n",
      "Time taken for acquisition score computation: 47.341856241226196\n",
      "For epoch 0: Train - Avg loss: 2.3055; Test - Avg loss: 2.3032, Accuracy: 512/5000 (10%)\n",
      "For epoch 1: Train - Avg loss: 2.3021; Test - Avg loss: 2.3025, Accuracy: 512/5000 (10%)\n",
      "For epoch 2: Train - Avg loss: 2.3021; Test - Avg loss: 2.2988, Accuracy: 512/5000 (10%)\n",
      "For epoch 3: Train - Avg loss: 2.2959; Test - Avg loss: 2.2698, Accuracy: 723/5000 (14%)\n",
      "For epoch 4: Train - Avg loss: 2.2837; Test - Avg loss: 2.2443, Accuracy: 947/5000 (19%)\n",
      "For epoch 5: Train - Avg loss: 2.2733; Test - Avg loss: 2.1670, Accuracy: 913/5000 (18%)\n",
      "For epoch 6: Train - Avg loss: 2.2433; Test - Avg loss: 2.0857, Accuracy: 1173/5000 (23%)\n",
      "For epoch 7: Train - Avg loss: 2.2341; Test - Avg loss: 2.1859, Accuracy: 989/5000 (20%)\n",
      "For epoch 8: Train - Avg loss: 2.2095; Test - Avg loss: 2.0077, Accuracy: 1296/5000 (26%)\n",
      "For epoch 9: Train - Avg loss: 2.1701; Test - Avg loss: 1.9589, Accuracy: 1449/5000 (29%)\n",
      "For epoch 10: Train - Avg loss: 2.1221; Test - Avg loss: 1.9234, Accuracy: 1373/5000 (27%)\n",
      "For epoch 11: Train - Avg loss: 2.0751; Test - Avg loss: 1.8736, Accuracy: 1512/5000 (30%)\n",
      "For epoch 12: Train - Avg loss: 1.9932; Test - Avg loss: 1.8062, Accuracy: 1528/5000 (31%)\n",
      "For epoch 13: Train - Avg loss: 1.9632; Test - Avg loss: 1.7602, Accuracy: 1686/5000 (34%)\n",
      "For epoch 14: Train - Avg loss: 1.8562; Test - Avg loss: 1.6650, Accuracy: 1870/5000 (37%)\n",
      "For epoch 15: Train - Avg loss: 1.8047; Test - Avg loss: 1.6587, Accuracy: 1907/5000 (38%)\n",
      "For epoch 16: Train - Avg loss: 1.7110; Test - Avg loss: 1.7115, Accuracy: 1868/5000 (37%)\n",
      "For epoch 17: Train - Avg loss: 1.6566; Test - Avg loss: 1.5991, Accuracy: 2071/5000 (41%)\n",
      "For epoch 18: Train - Avg loss: 1.5947; Test - Avg loss: 1.6475, Accuracy: 2038/5000 (41%)\n",
      "For epoch 19: Train - Avg loss: 1.4571; Test - Avg loss: 1.5538, Accuracy: 2243/5000 (45%)\n",
      "For epoch 20: Train - Avg loss: 1.3299; Test - Avg loss: 1.5548, Accuracy: 2256/5000 (45%)\n",
      "For epoch 21: Train - Avg loss: 1.2479; Test - Avg loss: 1.5266, Accuracy: 2311/5000 (46%)\n",
      "For epoch 22: Train - Avg loss: 1.1300; Test - Avg loss: 1.6609, Accuracy: 2221/5000 (44%)\n",
      "For epoch 23: Train - Avg loss: 1.0507; Test - Avg loss: 1.6123, Accuracy: 2347/5000 (47%)\n",
      "For epoch 24: Train - Avg loss: 0.9331; Test - Avg loss: 1.6685, Accuracy: 2430/5000 (49%)\n",
      "Test loss: 1.6891718021392823; Accuracy 4763/10000\n",
      "Acquiring BALD batch. acq_num: 15 Pool size: 8600\n",
      "Time taken for acquisition score computation: 48.18364405632019\n",
      "For epoch 0: Train - Avg loss: 2.3062; Test - Avg loss: 2.3022, Accuracy: 513/5000 (10%)\n",
      "For epoch 1: Train - Avg loss: 2.3001; Test - Avg loss: 2.2884, Accuracy: 512/5000 (10%)\n",
      "For epoch 2: Train - Avg loss: 2.2815; Test - Avg loss: 2.1873, Accuracy: 933/5000 (19%)\n",
      "For epoch 3: Train - Avg loss: 2.2634; Test - Avg loss: 2.1840, Accuracy: 1009/5000 (20%)\n",
      "For epoch 4: Train - Avg loss: 2.2444; Test - Avg loss: 2.1291, Accuracy: 1003/5000 (20%)\n",
      "For epoch 5: Train - Avg loss: 2.2199; Test - Avg loss: 2.0568, Accuracy: 1203/5000 (24%)\n",
      "For epoch 6: Train - Avg loss: 2.1917; Test - Avg loss: 2.0240, Accuracy: 1160/5000 (23%)\n",
      "For epoch 7: Train - Avg loss: 2.1784; Test - Avg loss: 2.0310, Accuracy: 1432/5000 (29%)\n",
      "For epoch 8: Train - Avg loss: 2.1529; Test - Avg loss: 1.9867, Accuracy: 1312/5000 (26%)\n",
      "For epoch 9: Train - Avg loss: 2.1090; Test - Avg loss: 1.8938, Accuracy: 1593/5000 (32%)\n",
      "For epoch 10: Train - Avg loss: 2.0468; Test - Avg loss: 1.8839, Accuracy: 1472/5000 (29%)\n",
      "For epoch 11: Train - Avg loss: 2.0469; Test - Avg loss: 1.8160, Accuracy: 1569/5000 (31%)\n",
      "For epoch 12: Train - Avg loss: 2.0098; Test - Avg loss: 1.8183, Accuracy: 1552/5000 (31%)\n",
      "For epoch 13: Train - Avg loss: 1.9516; Test - Avg loss: 1.7443, Accuracy: 1668/5000 (33%)\n",
      "For epoch 14: Train - Avg loss: 1.8625; Test - Avg loss: 1.6803, Accuracy: 1832/5000 (37%)\n",
      "For epoch 15: Train - Avg loss: 1.7959; Test - Avg loss: 1.7115, Accuracy: 1759/5000 (35%)\n",
      "For epoch 16: Train - Avg loss: 1.7451; Test - Avg loss: 1.6536, Accuracy: 1919/5000 (38%)\n",
      "For epoch 17: Train - Avg loss: 1.7022; Test - Avg loss: 1.6333, Accuracy: 2004/5000 (40%)\n",
      "For epoch 18: Train - Avg loss: 1.6139; Test - Avg loss: 1.6185, Accuracy: 1993/5000 (40%)\n",
      "For epoch 19: Train - Avg loss: 1.5439; Test - Avg loss: 1.6648, Accuracy: 2023/5000 (40%)\n",
      "For epoch 20: Train - Avg loss: 1.5229; Test - Avg loss: 1.6295, Accuracy: 2078/5000 (42%)\n",
      "For epoch 21: Train - Avg loss: 1.3830; Test - Avg loss: 1.6937, Accuracy: 2001/5000 (40%)\n",
      "For epoch 22: Train - Avg loss: 1.3745; Test - Avg loss: 1.5986, Accuracy: 2182/5000 (44%)\n",
      "For epoch 23: Train - Avg loss: 1.2190; Test - Avg loss: 1.6105, Accuracy: 2247/5000 (45%)\n",
      "For epoch 24: Train - Avg loss: 1.1388; Test - Avg loss: 1.6068, Accuracy: 2233/5000 (45%)\n",
      "Test loss: 1.6168589277267456; Accuracy 4470/10000\n",
      "Acquiring BALD batch. acq_num: 16 Pool size: 8500\n",
      "Time taken for acquisition score computation: 47.40797305107117\n",
      "For epoch 0: Train - Avg loss: 2.3049; Test - Avg loss: 2.3025, Accuracy: 471/5000 (9%)\n",
      "For epoch 1: Train - Avg loss: 2.2985; Test - Avg loss: 2.2877, Accuracy: 887/5000 (18%)\n",
      "For epoch 2: Train - Avg loss: 2.2858; Test - Avg loss: 2.2369, Accuracy: 727/5000 (15%)\n",
      "For epoch 3: Train - Avg loss: 2.2727; Test - Avg loss: 2.1770, Accuracy: 1119/5000 (22%)\n",
      "For epoch 4: Train - Avg loss: 2.2528; Test - Avg loss: 2.1442, Accuracy: 1063/5000 (21%)\n",
      "For epoch 5: Train - Avg loss: 2.2386; Test - Avg loss: 2.0695, Accuracy: 1228/5000 (25%)\n",
      "For epoch 6: Train - Avg loss: 2.1870; Test - Avg loss: 2.0075, Accuracy: 1307/5000 (26%)\n",
      "For epoch 7: Train - Avg loss: 2.1434; Test - Avg loss: 1.9870, Accuracy: 1188/5000 (24%)\n",
      "For epoch 8: Train - Avg loss: 2.1073; Test - Avg loss: 1.8465, Accuracy: 1547/5000 (31%)\n",
      "For epoch 9: Train - Avg loss: 2.0731; Test - Avg loss: 1.8475, Accuracy: 1598/5000 (32%)\n",
      "For epoch 10: Train - Avg loss: 2.0040; Test - Avg loss: 1.7678, Accuracy: 1694/5000 (34%)\n",
      "For epoch 11: Train - Avg loss: 1.9950; Test - Avg loss: 1.7210, Accuracy: 1778/5000 (36%)\n",
      "For epoch 12: Train - Avg loss: 1.9154; Test - Avg loss: 1.6936, Accuracy: 1879/5000 (38%)\n",
      "For epoch 13: Train - Avg loss: 1.8533; Test - Avg loss: 1.6498, Accuracy: 1926/5000 (39%)\n",
      "For epoch 14: Train - Avg loss: 1.7781; Test - Avg loss: 1.6182, Accuracy: 1961/5000 (39%)\n",
      "For epoch 15: Train - Avg loss: 1.7862; Test - Avg loss: 1.5727, Accuracy: 2139/5000 (43%)\n",
      "For epoch 16: Train - Avg loss: 1.6556; Test - Avg loss: 1.5313, Accuracy: 2131/5000 (43%)\n",
      "For epoch 17: Train - Avg loss: 1.6437; Test - Avg loss: 1.6269, Accuracy: 2013/5000 (40%)\n",
      "For epoch 18: Train - Avg loss: 1.5745; Test - Avg loss: 1.6141, Accuracy: 2080/5000 (42%)\n",
      "For epoch 19: Train - Avg loss: 1.4818; Test - Avg loss: 1.5285, Accuracy: 2239/5000 (45%)\n",
      "For epoch 20: Train - Avg loss: 1.3698; Test - Avg loss: 1.5279, Accuracy: 2265/5000 (45%)\n",
      "For epoch 21: Train - Avg loss: 1.2551; Test - Avg loss: 1.6845, Accuracy: 2170/5000 (43%)\n",
      "For epoch 22: Train - Avg loss: 1.2717; Test - Avg loss: 1.5574, Accuracy: 2343/5000 (47%)\n",
      "For epoch 23: Train - Avg loss: 1.1596; Test - Avg loss: 1.5608, Accuracy: 2358/5000 (47%)\n",
      "For epoch 24: Train - Avg loss: 1.0533; Test - Avg loss: 1.7624, Accuracy: 2245/5000 (45%)\n",
      "Test loss: 1.758631600189209; Accuracy 4421/10000\n",
      "Acquiring BALD batch. acq_num: 17 Pool size: 8400\n",
      "Time taken for acquisition score computation: 46.24165678024292\n",
      "For epoch 0: Train - Avg loss: 2.3035; Test - Avg loss: 2.3032, Accuracy: 500/5000 (10%)\n",
      "For epoch 1: Train - Avg loss: 2.3015; Test - Avg loss: 2.2958, Accuracy: 500/5000 (10%)\n",
      "For epoch 2: Train - Avg loss: 2.2949; Test - Avg loss: 2.2468, Accuracy: 754/5000 (15%)\n",
      "For epoch 3: Train - Avg loss: 2.2516; Test - Avg loss: 2.1157, Accuracy: 887/5000 (18%)\n",
      "For epoch 4: Train - Avg loss: 2.2272; Test - Avg loss: 2.0541, Accuracy: 1028/5000 (21%)\n",
      "For epoch 5: Train - Avg loss: 2.1936; Test - Avg loss: 2.0624, Accuracy: 1193/5000 (24%)\n",
      "For epoch 6: Train - Avg loss: 2.1475; Test - Avg loss: 1.9362, Accuracy: 1254/5000 (25%)\n",
      "For epoch 7: Train - Avg loss: 2.1109; Test - Avg loss: 1.9134, Accuracy: 1359/5000 (27%)\n",
      "For epoch 8: Train - Avg loss: 2.1021; Test - Avg loss: 1.8708, Accuracy: 1409/5000 (28%)\n",
      "For epoch 9: Train - Avg loss: 2.0448; Test - Avg loss: 1.8291, Accuracy: 1566/5000 (31%)\n",
      "For epoch 10: Train - Avg loss: 2.0029; Test - Avg loss: 1.7994, Accuracy: 1707/5000 (34%)\n",
      "For epoch 11: Train - Avg loss: 1.9368; Test - Avg loss: 1.7230, Accuracy: 1773/5000 (35%)\n",
      "For epoch 12: Train - Avg loss: 1.9216; Test - Avg loss: 1.7136, Accuracy: 1820/5000 (36%)\n",
      "For epoch 13: Train - Avg loss: 1.8204; Test - Avg loss: 1.5968, Accuracy: 2020/5000 (40%)\n",
      "For epoch 14: Train - Avg loss: 1.7606; Test - Avg loss: 1.5514, Accuracy: 2131/5000 (43%)\n",
      "For epoch 15: Train - Avg loss: 1.6865; Test - Avg loss: 1.5513, Accuracy: 2156/5000 (43%)\n",
      "For epoch 16: Train - Avg loss: 1.6155; Test - Avg loss: 1.5185, Accuracy: 2171/5000 (43%)\n",
      "For epoch 17: Train - Avg loss: 1.5689; Test - Avg loss: 1.5607, Accuracy: 2147/5000 (43%)\n",
      "For epoch 18: Train - Avg loss: 1.4947; Test - Avg loss: 1.4602, Accuracy: 2333/5000 (47%)\n",
      "For epoch 19: Train - Avg loss: 1.4047; Test - Avg loss: 1.4666, Accuracy: 2354/5000 (47%)\n",
      "For epoch 20: Train - Avg loss: 1.2872; Test - Avg loss: 1.5083, Accuracy: 2350/5000 (47%)\n",
      "For epoch 21: Train - Avg loss: 1.2075; Test - Avg loss: 1.5023, Accuracy: 2363/5000 (47%)\n",
      "For epoch 22: Train - Avg loss: 1.1346; Test - Avg loss: 1.4749, Accuracy: 2527/5000 (51%)\n",
      "For epoch 23: Train - Avg loss: 0.9938; Test - Avg loss: 1.5151, Accuracy: 2487/5000 (50%)\n",
      "For epoch 24: Train - Avg loss: 0.9215; Test - Avg loss: 1.5427, Accuracy: 2532/5000 (51%)\n",
      "Test loss: 1.5837662298202515; Accuracy 4828/10000\n",
      "Acquiring BALD batch. acq_num: 18 Pool size: 8300\n",
      "Time taken for acquisition score computation: 45.55137825012207\n",
      "For epoch 0: Train - Avg loss: 2.3047; Test - Avg loss: 2.3035, Accuracy: 471/5000 (9%)\n",
      "For epoch 1: Train - Avg loss: 2.3021; Test - Avg loss: 2.3029, Accuracy: 471/5000 (9%)\n",
      "For epoch 2: Train - Avg loss: 2.2990; Test - Avg loss: 2.3009, Accuracy: 552/5000 (11%)\n",
      "For epoch 3: Train - Avg loss: 2.2982; Test - Avg loss: 2.2594, Accuracy: 747/5000 (15%)\n",
      "For epoch 4: Train - Avg loss: 2.2612; Test - Avg loss: 2.1541, Accuracy: 1151/5000 (23%)\n",
      "For epoch 5: Train - Avg loss: 2.2235; Test - Avg loss: 2.0921, Accuracy: 1309/5000 (26%)\n",
      "For epoch 6: Train - Avg loss: 2.1961; Test - Avg loss: 2.0749, Accuracy: 1446/5000 (29%)\n",
      "For epoch 7: Train - Avg loss: 2.1656; Test - Avg loss: 1.9620, Accuracy: 1475/5000 (30%)\n",
      "For epoch 8: Train - Avg loss: 2.1019; Test - Avg loss: 1.8637, Accuracy: 1584/5000 (32%)\n",
      "For epoch 9: Train - Avg loss: 2.0436; Test - Avg loss: 1.8483, Accuracy: 1676/5000 (34%)\n",
      "For epoch 10: Train - Avg loss: 1.9967; Test - Avg loss: 1.7811, Accuracy: 1731/5000 (35%)\n",
      "For epoch 11: Train - Avg loss: 1.9663; Test - Avg loss: 1.7458, Accuracy: 1813/5000 (36%)\n",
      "For epoch 12: Train - Avg loss: 1.8905; Test - Avg loss: 1.6721, Accuracy: 1930/5000 (39%)\n",
      "For epoch 13: Train - Avg loss: 1.8184; Test - Avg loss: 1.6414, Accuracy: 1978/5000 (40%)\n",
      "For epoch 14: Train - Avg loss: 1.7706; Test - Avg loss: 1.6371, Accuracy: 2013/5000 (40%)\n",
      "For epoch 15: Train - Avg loss: 1.6613; Test - Avg loss: 1.5387, Accuracy: 2191/5000 (44%)\n",
      "For epoch 16: Train - Avg loss: 1.5287; Test - Avg loss: 1.5359, Accuracy: 2193/5000 (44%)\n",
      "For epoch 17: Train - Avg loss: 1.4876; Test - Avg loss: 1.5459, Accuracy: 2197/5000 (44%)\n",
      "For epoch 18: Train - Avg loss: 1.3700; Test - Avg loss: 1.6028, Accuracy: 2252/5000 (45%)\n",
      "For epoch 19: Train - Avg loss: 1.2886; Test - Avg loss: 1.5757, Accuracy: 2274/5000 (45%)\n",
      "For epoch 20: Train - Avg loss: 1.1324; Test - Avg loss: 1.5595, Accuracy: 2344/5000 (47%)\n",
      "For epoch 21: Train - Avg loss: 1.0484; Test - Avg loss: 1.6782, Accuracy: 2338/5000 (47%)\n",
      "For epoch 22: Train - Avg loss: 0.9501; Test - Avg loss: 1.6388, Accuracy: 2402/5000 (48%)\n",
      "For epoch 23: Train - Avg loss: 0.8407; Test - Avg loss: 1.6843, Accuracy: 2383/5000 (48%)\n",
      "For epoch 24: Train - Avg loss: 0.7330; Test - Avg loss: 1.7737, Accuracy: 2401/5000 (48%)\n",
      "Test loss: 1.8085021436691284; Accuracy 4678/10000\n",
      "Acquiring BALD batch. acq_num: 19 Pool size: 8200\n",
      "Time taken for acquisition score computation: 47.110055685043335\n",
      "For epoch 0: Train - Avg loss: 2.3027; Test - Avg loss: 2.3001, Accuracy: 490/5000 (10%)\n",
      "For epoch 1: Train - Avg loss: 2.2971; Test - Avg loss: 2.2697, Accuracy: 660/5000 (13%)\n",
      "For epoch 2: Train - Avg loss: 2.2645; Test - Avg loss: 2.1500, Accuracy: 984/5000 (20%)\n",
      "For epoch 3: Train - Avg loss: 2.2415; Test - Avg loss: 2.1110, Accuracy: 1137/5000 (23%)\n",
      "For epoch 4: Train - Avg loss: 2.2135; Test - Avg loss: 2.0549, Accuracy: 1228/5000 (25%)\n",
      "For epoch 5: Train - Avg loss: 2.1663; Test - Avg loss: 1.9485, Accuracy: 1451/5000 (29%)\n",
      "For epoch 6: Train - Avg loss: 2.1205; Test - Avg loss: 1.9019, Accuracy: 1479/5000 (30%)\n",
      "For epoch 7: Train - Avg loss: 2.0749; Test - Avg loss: 1.8525, Accuracy: 1607/5000 (32%)\n",
      "For epoch 8: Train - Avg loss: 2.0089; Test - Avg loss: 1.7449, Accuracy: 1801/5000 (36%)\n",
      "For epoch 9: Train - Avg loss: 1.9468; Test - Avg loss: 1.7421, Accuracy: 1737/5000 (35%)\n",
      "For epoch 10: Train - Avg loss: 1.8714; Test - Avg loss: 1.6069, Accuracy: 2049/5000 (41%)\n",
      "For epoch 11: Train - Avg loss: 1.8077; Test - Avg loss: 1.5652, Accuracy: 2071/5000 (41%)\n",
      "For epoch 12: Train - Avg loss: 1.7480; Test - Avg loss: 1.5543, Accuracy: 2014/5000 (40%)\n",
      "For epoch 13: Train - Avg loss: 1.6851; Test - Avg loss: 1.5581, Accuracy: 2119/5000 (42%)\n",
      "For epoch 14: Train - Avg loss: 1.6328; Test - Avg loss: 1.4776, Accuracy: 2313/5000 (46%)\n",
      "For epoch 15: Train - Avg loss: 1.4896; Test - Avg loss: 1.4357, Accuracy: 2398/5000 (48%)\n",
      "For epoch 16: Train - Avg loss: 1.4309; Test - Avg loss: 1.4702, Accuracy: 2330/5000 (47%)\n",
      "For epoch 17: Train - Avg loss: 1.3404; Test - Avg loss: 1.4508, Accuracy: 2358/5000 (47%)\n",
      "For epoch 18: Train - Avg loss: 1.2534; Test - Avg loss: 1.4765, Accuracy: 2349/5000 (47%)\n",
      "For epoch 19: Train - Avg loss: 1.1424; Test - Avg loss: 1.4707, Accuracy: 2508/5000 (50%)\n",
      "For epoch 20: Train - Avg loss: 1.0462; Test - Avg loss: 1.4510, Accuracy: 2513/5000 (50%)\n",
      "For epoch 21: Train - Avg loss: 0.9458; Test - Avg loss: 1.5295, Accuracy: 2486/5000 (50%)\n",
      "For epoch 22: Train - Avg loss: 0.9242; Test - Avg loss: 1.6150, Accuracy: 2406/5000 (48%)\n",
      "For epoch 23: Train - Avg loss: 0.8044; Test - Avg loss: 1.5185, Accuracy: 2644/5000 (53%)\n",
      "For epoch 24: Train - Avg loss: 0.7317; Test - Avg loss: 1.6121, Accuracy: 2628/5000 (53%)\n",
      "Test loss: 1.6776127494812012; Accuracy 5094/10000\n",
      "Acquiring BALD batch. acq_num: 20 Pool size: 8100\n",
      "Time taken for acquisition score computation: 45.024463415145874\n",
      "For epoch 0: Train - Avg loss: 2.3035; Test - Avg loss: 2.3024, Accuracy: 488/5000 (10%)\n",
      "For epoch 1: Train - Avg loss: 2.2901; Test - Avg loss: 2.2524, Accuracy: 794/5000 (16%)\n",
      "For epoch 2: Train - Avg loss: 2.3031; Test - Avg loss: 2.2880, Accuracy: 555/5000 (11%)\n",
      "For epoch 3: Train - Avg loss: 2.2736; Test - Avg loss: 2.1730, Accuracy: 877/5000 (18%)\n",
      "For epoch 4: Train - Avg loss: 2.2420; Test - Avg loss: 2.1497, Accuracy: 916/5000 (18%)\n",
      "For epoch 5: Train - Avg loss: 2.2382; Test - Avg loss: 2.1393, Accuracy: 1129/5000 (23%)\n",
      "For epoch 6: Train - Avg loss: 2.2226; Test - Avg loss: 2.1105, Accuracy: 1204/5000 (24%)\n",
      "For epoch 7: Train - Avg loss: 2.2039; Test - Avg loss: 2.0770, Accuracy: 1176/5000 (24%)\n",
      "For epoch 8: Train - Avg loss: 2.1875; Test - Avg loss: 2.0446, Accuracy: 1242/5000 (25%)\n",
      "For epoch 9: Train - Avg loss: 2.1741; Test - Avg loss: 2.0346, Accuracy: 1313/5000 (26%)\n",
      "For epoch 10: Train - Avg loss: 2.1580; Test - Avg loss: 2.0432, Accuracy: 1404/5000 (28%)\n",
      "For epoch 11: Train - Avg loss: 2.1276; Test - Avg loss: 1.8996, Accuracy: 1566/5000 (31%)\n",
      "For epoch 12: Train - Avg loss: 2.0560; Test - Avg loss: 1.8705, Accuracy: 1519/5000 (30%)\n",
      "For epoch 13: Train - Avg loss: 2.0513; Test - Avg loss: 1.8413, Accuracy: 1568/5000 (31%)\n",
      "For epoch 14: Train - Avg loss: 2.0122; Test - Avg loss: 1.7719, Accuracy: 1751/5000 (35%)\n",
      "For epoch 15: Train - Avg loss: 1.9284; Test - Avg loss: 1.6974, Accuracy: 1840/5000 (37%)\n",
      "For epoch 16: Train - Avg loss: 1.8933; Test - Avg loss: 1.6968, Accuracy: 1877/5000 (38%)\n",
      "For epoch 17: Train - Avg loss: 1.8100; Test - Avg loss: 1.6449, Accuracy: 1931/5000 (39%)\n",
      "For epoch 18: Train - Avg loss: 1.7395; Test - Avg loss: 1.6725, Accuracy: 2038/5000 (41%)\n",
      "For epoch 19: Train - Avg loss: 1.6703; Test - Avg loss: 1.6181, Accuracy: 2039/5000 (41%)\n",
      "For epoch 20: Train - Avg loss: 1.6275; Test - Avg loss: 1.5498, Accuracy: 2183/5000 (44%)\n",
      "For epoch 21: Train - Avg loss: 1.5429; Test - Avg loss: 1.5258, Accuracy: 2283/5000 (46%)\n",
      "For epoch 22: Train - Avg loss: 1.4557; Test - Avg loss: 1.6102, Accuracy: 2049/5000 (41%)\n",
      "For epoch 23: Train - Avg loss: 1.3998; Test - Avg loss: 1.5127, Accuracy: 2336/5000 (47%)\n",
      "For epoch 24: Train - Avg loss: 1.3062; Test - Avg loss: 1.5415, Accuracy: 2379/5000 (48%)\n",
      "Test loss: 1.5682131044387817; Accuracy 4617/10000\n",
      "Acquiring BALD batch. acq_num: 21 Pool size: 8000\n",
      "Time taken for acquisition score computation: 45.052162408828735\n",
      "For epoch 0: Train - Avg loss: 2.3035; Test - Avg loss: 2.3034, Accuracy: 500/5000 (10%)\n",
      "For epoch 1: Train - Avg loss: 2.3020; Test - Avg loss: 2.3033, Accuracy: 500/5000 (10%)\n",
      "For epoch 2: Train - Avg loss: 2.2938; Test - Avg loss: 2.2072, Accuracy: 909/5000 (18%)\n",
      "For epoch 3: Train - Avg loss: 2.2523; Test - Avg loss: 2.1303, Accuracy: 940/5000 (19%)\n",
      "For epoch 4: Train - Avg loss: 2.2407; Test - Avg loss: 2.0978, Accuracy: 1013/5000 (20%)\n",
      "For epoch 5: Train - Avg loss: 2.2163; Test - Avg loss: 2.0798, Accuracy: 1157/5000 (23%)\n",
      "For epoch 6: Train - Avg loss: 2.1926; Test - Avg loss: 2.0189, Accuracy: 1255/5000 (25%)\n",
      "For epoch 7: Train - Avg loss: 2.1602; Test - Avg loss: 1.9428, Accuracy: 1409/5000 (28%)\n",
      "For epoch 8: Train - Avg loss: 2.1238; Test - Avg loss: 1.8739, Accuracy: 1517/5000 (30%)\n",
      "For epoch 9: Train - Avg loss: 2.1065; Test - Avg loss: 1.8517, Accuracy: 1692/5000 (34%)\n",
      "For epoch 10: Train - Avg loss: 2.0485; Test - Avg loss: 1.7998, Accuracy: 1708/5000 (34%)\n",
      "For epoch 11: Train - Avg loss: 1.9888; Test - Avg loss: 1.7130, Accuracy: 1764/5000 (35%)\n",
      "For epoch 12: Train - Avg loss: 1.9586; Test - Avg loss: 1.7073, Accuracy: 1738/5000 (35%)\n",
      "For epoch 13: Train - Avg loss: 1.8997; Test - Avg loss: 1.6872, Accuracy: 1744/5000 (35%)\n",
      "For epoch 14: Train - Avg loss: 1.8299; Test - Avg loss: 1.6159, Accuracy: 1907/5000 (38%)\n",
      "For epoch 15: Train - Avg loss: 1.7858; Test - Avg loss: 1.6150, Accuracy: 1981/5000 (40%)\n",
      "For epoch 16: Train - Avg loss: 1.7357; Test - Avg loss: 1.5945, Accuracy: 2064/5000 (41%)\n",
      "For epoch 17: Train - Avg loss: 1.6527; Test - Avg loss: 1.5605, Accuracy: 2076/5000 (42%)\n",
      "For epoch 18: Train - Avg loss: 1.5717; Test - Avg loss: 1.5598, Accuracy: 2082/5000 (42%)\n",
      "For epoch 19: Train - Avg loss: 1.5502; Test - Avg loss: 1.5368, Accuracy: 2188/5000 (44%)\n",
      "For epoch 20: Train - Avg loss: 1.4414; Test - Avg loss: 1.5284, Accuracy: 2203/5000 (44%)\n",
      "For epoch 21: Train - Avg loss: 1.3057; Test - Avg loss: 1.5029, Accuracy: 2365/5000 (47%)\n",
      "For epoch 22: Train - Avg loss: 1.2251; Test - Avg loss: 1.5406, Accuracy: 2377/5000 (48%)\n",
      "For epoch 23: Train - Avg loss: 1.0747; Test - Avg loss: 1.5570, Accuracy: 2404/5000 (48%)\n",
      "For epoch 24: Train - Avg loss: 1.0398; Test - Avg loss: 1.6459, Accuracy: 2389/5000 (48%)\n",
      "Test loss: 1.6530585596084595; Accuracy 4639/10000\n",
      "Acquiring BALD batch. acq_num: 22 Pool size: 7900\n",
      "Time taken for acquisition score computation: 43.752015829086304\n",
      "For epoch 0: Train - Avg loss: 2.3047; Test - Avg loss: 2.3039, Accuracy: 501/5000 (10%)\n",
      "For epoch 1: Train - Avg loss: 2.2992; Test - Avg loss: 2.2844, Accuracy: 662/5000 (13%)\n",
      "For epoch 2: Train - Avg loss: 2.2916; Test - Avg loss: 2.2516, Accuracy: 823/5000 (16%)\n",
      "For epoch 3: Train - Avg loss: 2.2736; Test - Avg loss: 2.2087, Accuracy: 965/5000 (19%)\n",
      "For epoch 4: Train - Avg loss: 2.2421; Test - Avg loss: 2.1201, Accuracy: 1059/5000 (21%)\n",
      "For epoch 5: Train - Avg loss: 2.2294; Test - Avg loss: 2.1268, Accuracy: 1104/5000 (22%)\n",
      "For epoch 6: Train - Avg loss: 2.1916; Test - Avg loss: 2.0174, Accuracy: 1180/5000 (24%)\n",
      "For epoch 7: Train - Avg loss: 2.1491; Test - Avg loss: 1.9803, Accuracy: 1345/5000 (27%)\n",
      "For epoch 8: Train - Avg loss: 2.1133; Test - Avg loss: 1.9405, Accuracy: 1395/5000 (28%)\n",
      "For epoch 9: Train - Avg loss: 2.0971; Test - Avg loss: 1.8863, Accuracy: 1494/5000 (30%)\n",
      "For epoch 10: Train - Avg loss: 2.0531; Test - Avg loss: 1.7624, Accuracy: 1658/5000 (33%)\n",
      "For epoch 11: Train - Avg loss: 1.9571; Test - Avg loss: 1.6931, Accuracy: 1886/5000 (38%)\n",
      "For epoch 12: Train - Avg loss: 1.9017; Test - Avg loss: 1.6843, Accuracy: 1829/5000 (37%)\n",
      "For epoch 13: Train - Avg loss: 1.8244; Test - Avg loss: 1.5812, Accuracy: 2094/5000 (42%)\n",
      "For epoch 14: Train - Avg loss: 1.7237; Test - Avg loss: 1.5633, Accuracy: 2114/5000 (42%)\n",
      "For epoch 15: Train - Avg loss: 1.6352; Test - Avg loss: 1.5133, Accuracy: 2219/5000 (44%)\n",
      "For epoch 16: Train - Avg loss: 1.5580; Test - Avg loss: 1.4837, Accuracy: 2244/5000 (45%)\n",
      "For epoch 17: Train - Avg loss: 1.4781; Test - Avg loss: 1.5188, Accuracy: 2225/5000 (44%)\n",
      "For epoch 18: Train - Avg loss: 1.3673; Test - Avg loss: 1.5103, Accuracy: 2302/5000 (46%)\n",
      "For epoch 19: Train - Avg loss: 1.2639; Test - Avg loss: 1.5694, Accuracy: 2335/5000 (47%)\n",
      "For epoch 20: Train - Avg loss: 1.1634; Test - Avg loss: 1.5387, Accuracy: 2389/5000 (48%)\n",
      "For epoch 21: Train - Avg loss: 1.0779; Test - Avg loss: 1.5645, Accuracy: 2383/5000 (48%)\n",
      "For epoch 22: Train - Avg loss: 0.9832; Test - Avg loss: 1.6415, Accuracy: 2394/5000 (48%)\n",
      "For epoch 23: Train - Avg loss: 0.9227; Test - Avg loss: 1.6742, Accuracy: 2474/5000 (49%)\n",
      "For epoch 24: Train - Avg loss: 0.8087; Test - Avg loss: 1.7056, Accuracy: 2468/5000 (49%)\n",
      "Test loss: 1.7267783666610719; Accuracy 4846/10000\n",
      "Acquiring BALD batch. acq_num: 23 Pool size: 7800\n",
      "Time taken for acquisition score computation: 43.07222294807434\n",
      "For epoch 0: Train - Avg loss: 2.3023; Test - Avg loss: 2.3014, Accuracy: 451/5000 (9%)\n",
      "For epoch 1: Train - Avg loss: 2.2950; Test - Avg loss: 2.3131, Accuracy: 497/5000 (10%)\n",
      "For epoch 2: Train - Avg loss: 2.2781; Test - Avg loss: 2.2054, Accuracy: 831/5000 (17%)\n",
      "For epoch 3: Train - Avg loss: 2.2573; Test - Avg loss: 2.1338, Accuracy: 870/5000 (17%)\n",
      "For epoch 4: Train - Avg loss: 2.2097; Test - Avg loss: 2.0215, Accuracy: 1125/5000 (22%)\n",
      "For epoch 5: Train - Avg loss: 2.1805; Test - Avg loss: 1.9222, Accuracy: 1360/5000 (27%)\n",
      "For epoch 6: Train - Avg loss: 2.1394; Test - Avg loss: 1.8684, Accuracy: 1524/5000 (30%)\n",
      "For epoch 7: Train - Avg loss: 2.0902; Test - Avg loss: 1.8825, Accuracy: 1456/5000 (29%)\n",
      "For epoch 8: Train - Avg loss: 2.0500; Test - Avg loss: 1.7942, Accuracy: 1599/5000 (32%)\n",
      "For epoch 9: Train - Avg loss: 1.9998; Test - Avg loss: 1.7062, Accuracy: 1730/5000 (35%)\n",
      "For epoch 10: Train - Avg loss: 1.9447; Test - Avg loss: 1.6279, Accuracy: 1915/5000 (38%)\n",
      "For epoch 11: Train - Avg loss: 1.8285; Test - Avg loss: 1.6553, Accuracy: 1882/5000 (38%)\n",
      "For epoch 12: Train - Avg loss: 1.8109; Test - Avg loss: 1.5954, Accuracy: 2035/5000 (41%)\n",
      "For epoch 13: Train - Avg loss: 1.7222; Test - Avg loss: 1.4984, Accuracy: 2101/5000 (42%)\n",
      "For epoch 14: Train - Avg loss: 1.6263; Test - Avg loss: 1.5170, Accuracy: 2156/5000 (43%)\n",
      "For epoch 15: Train - Avg loss: 1.5266; Test - Avg loss: 1.4794, Accuracy: 2193/5000 (44%)\n",
      "For epoch 16: Train - Avg loss: 1.4229; Test - Avg loss: 1.4453, Accuracy: 2421/5000 (48%)\n",
      "For epoch 17: Train - Avg loss: 1.3108; Test - Avg loss: 1.5104, Accuracy: 2334/5000 (47%)\n",
      "For epoch 18: Train - Avg loss: 1.3574; Test - Avg loss: 1.5626, Accuracy: 2212/5000 (44%)\n",
      "For epoch 19: Train - Avg loss: 1.2605; Test - Avg loss: 1.4341, Accuracy: 2532/5000 (51%)\n",
      "For epoch 20: Train - Avg loss: 1.0524; Test - Avg loss: 1.4565, Accuracy: 2546/5000 (51%)\n",
      "For epoch 21: Train - Avg loss: 0.9414; Test - Avg loss: 1.5195, Accuracy: 2548/5000 (51%)\n",
      "For epoch 22: Train - Avg loss: 0.8868; Test - Avg loss: 1.5401, Accuracy: 2592/5000 (52%)\n",
      "For epoch 23: Train - Avg loss: 0.7714; Test - Avg loss: 1.7723, Accuracy: 2498/5000 (50%)\n",
      "For epoch 24: Train - Avg loss: 0.7286; Test - Avg loss: 1.5922, Accuracy: 2668/5000 (53%)\n",
      "Test loss: 1.6688280025482178; Accuracy 5154/10000\n",
      "Acquiring BALD batch. acq_num: 24 Pool size: 7700\n",
      "Time taken for acquisition score computation: 42.2767698764801\n",
      "For epoch 0: Train - Avg loss: 2.3022; Test - Avg loss: 2.3013, Accuracy: 471/5000 (9%)\n",
      "For epoch 1: Train - Avg loss: 2.2892; Test - Avg loss: 2.2467, Accuracy: 687/5000 (14%)\n",
      "For epoch 2: Train - Avg loss: 2.2595; Test - Avg loss: 2.1744, Accuracy: 989/5000 (20%)\n",
      "For epoch 3: Train - Avg loss: 2.2323; Test - Avg loss: 2.1479, Accuracy: 1021/5000 (20%)\n",
      "For epoch 4: Train - Avg loss: 2.1958; Test - Avg loss: 1.9711, Accuracy: 1413/5000 (28%)\n",
      "For epoch 5: Train - Avg loss: 2.1481; Test - Avg loss: 1.8993, Accuracy: 1546/5000 (31%)\n",
      "For epoch 6: Train - Avg loss: 2.0842; Test - Avg loss: 1.8380, Accuracy: 1633/5000 (33%)\n",
      "For epoch 7: Train - Avg loss: 2.0422; Test - Avg loss: 1.7721, Accuracy: 1728/5000 (35%)\n",
      "For epoch 8: Train - Avg loss: 1.9882; Test - Avg loss: 1.6586, Accuracy: 2030/5000 (41%)\n",
      "For epoch 9: Train - Avg loss: 1.9165; Test - Avg loss: 1.6430, Accuracy: 1919/5000 (38%)\n",
      "For epoch 10: Train - Avg loss: 1.8627; Test - Avg loss: 1.5664, Accuracy: 2057/5000 (41%)\n",
      "For epoch 11: Train - Avg loss: 1.8255; Test - Avg loss: 1.5277, Accuracy: 2159/5000 (43%)\n",
      "For epoch 12: Train - Avg loss: 1.7438; Test - Avg loss: 1.5233, Accuracy: 2102/5000 (42%)\n",
      "For epoch 13: Train - Avg loss: 1.6628; Test - Avg loss: 1.4907, Accuracy: 2179/5000 (44%)\n",
      "For epoch 14: Train - Avg loss: 1.5578; Test - Avg loss: 1.4464, Accuracy: 2319/5000 (46%)\n",
      "For epoch 15: Train - Avg loss: 1.4485; Test - Avg loss: 1.4293, Accuracy: 2389/5000 (48%)\n",
      "For epoch 16: Train - Avg loss: 1.3889; Test - Avg loss: 1.4043, Accuracy: 2447/5000 (49%)\n",
      "For epoch 17: Train - Avg loss: 1.2375; Test - Avg loss: 1.4837, Accuracy: 2393/5000 (48%)\n",
      "For epoch 18: Train - Avg loss: 1.1612; Test - Avg loss: 1.4119, Accuracy: 2545/5000 (51%)\n",
      "For epoch 19: Train - Avg loss: 1.0709; Test - Avg loss: 1.4045, Accuracy: 2584/5000 (52%)\n",
      "For epoch 20: Train - Avg loss: 0.9708; Test - Avg loss: 1.4731, Accuracy: 2571/5000 (51%)\n",
      "For epoch 21: Train - Avg loss: 0.8569; Test - Avg loss: 1.5651, Accuracy: 2574/5000 (51%)\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 3.81 GiB of which 12.38 MiB is free. Including non-PyTorch memory, this process has 3.48 GiB memory in use. Process 327155712 has 0 bytes memory in use. Of the allocated memory 3.05 GiB is allocated by PyTorch, and 319.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[61], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlr)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m---> 16\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m     correct, test_loss \u001b[38;5;241m=\u001b[39m test(model, val_loader)\n\u001b[1;32m     18\u001b[0m     print_losses(epoch, train_loss, test_loss, correct, \u001b[38;5;28mlen\u001b[39m(val_dataset))\n",
      "Cell \u001b[0;32mIn[48], line 12\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model_, train_loader, optimizer)\u001b[0m\n\u001b[1;32m     10\u001b[0m     loss \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mcross_entropy(output, target)\n\u001b[1;32m     11\u001b[0m     avg_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\n\u001b[0;32m---> 12\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m avg_loss \u001b[38;5;241m/\u001b[39m epoch_size\n",
      "File \u001b[0;32m~/anaconda3/envs/conda-torch/lib/python3.10/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/conda-torch/lib/python3.10/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 3.81 GiB of which 12.38 MiB is free. Including non-PyTorch memory, this process has 3.48 GiB memory in use. Process 327155712 has 0 bytes memory in use. Of the allocated memory 3.05 GiB is allocated by PyTorch, and 319.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "test_accuracies = []\n",
    "acq_num = 1\n",
    "acc_test = 0.0\n",
    "train_dataset = pretrain_dataset\n",
    "\n",
    "# start with a pretrained model on the pretraining data\n",
    "# also should have obtained the subnet\n",
    "while len(pool_dataset) > 0 and acc_test <= 0.58 and acq_num <= 30:\n",
    "    # train on it\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=train_batch_size, pin_memory=True, shuffle=True\n",
    "    )\n",
    "    model = Net().to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    for epoch in range(epochs):\n",
    "        train_loss = train(model, train_loader, optimizer)\n",
    "        correct, test_loss = test(model, val_loader)\n",
    "        print_losses(epoch, train_loss, test_loss, correct, len(val_dataset))\n",
    "        subnet.update_model_variances(epoch, epochs)\n",
    "\n",
    "    # test the accuracy\n",
    "    correct, test_loss = test(model, test_loader)\n",
    "    acc_test = correct / len(test_dataset)\n",
    "    test_accuracies.append(acc_test)\n",
    "    print(f\"Test loss: {test_loss}; Accuracy {correct}/{len(test_dataset)}\")\n",
    "\n",
    "    subnet_mask_indices = subnet.get_mask_indices()\n",
    "    params_dict, buffers_dict = generate_dicts(model)\n",
    "    posterior_covariance = calculate_ggn(model, train_dataset, subnet_mask_indices)\n",
    "\n",
    "    print(f\"Acquiring BALD batch. acq_num: {acq_num} Pool size: {len(pool_dataset)}\")\n",
    "    # get the indices of the best batch of data\n",
    "    start_time = time.time()\n",
    "    batch_indices = select_batch(\n",
    "        model, pool_dataset, subnet_mask_indices, posterior_covariance\n",
    "    )\n",
    "    end_time = time.time()\n",
    "    print(f\"Time taken for acquisition score computation: {end_time - start_time}\")\n",
    "\n",
    "    # move that data from the pool to the training set\n",
    "    move_data(batch_indices, pool_dataset, train_dataset)\n",
    "\n",
    "    acq_num = acq_num + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pk\n",
    "\n",
    "with open(\"./tmp/test_accuracies_ppd2.pickle\", \"wb\") as f:\n",
    "    pk.dump(test_accuracies, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = range(0, len(test_accuracies))\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(epochs, test_accuracies, marker=\"o\")\n",
    "plt.title(\"Test Accuracies\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xticks(epochs)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda-torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
