{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jYvBjyNxAuVM",
    "outputId": "df98c75f-3c61-4e7e-d315-cd30ab927636"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ba13/anaconda3/envs/conda-torch/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/ba13/anaconda3/envs/conda-torch/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSs'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device {device}\")\n",
    "\n",
    "# Load the MNIST dataset\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transforms.ToTensor())\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the neural network\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3)\n",
    "        self.pool = nn.AvgPool2d(kernel_size=2)\n",
    "        self.fc1 = nn.Linear(64 * 5 * 5, 64 * 5 * 5)\n",
    "        self.fc2 = nn.Linear(64 * 5 * 5, 128)\n",
    "        self.fc3 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.tanh(self.conv1(x)))\n",
    "        x = self.pool(torch.tanh(self.conv2(x)))\n",
    "        x = x.view(-1, 64 * 5 * 5)\n",
    "        x = torch.tanh(self.fc1(x))\n",
    "        x = torch.tanh(self.fc2(x))\n",
    "        x = torch.softmax(self.fc3(x), dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2786634"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the network\n",
    "net = Net().to(device)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters())\n",
    "\n",
    "# model parameters\n",
    "sum(p.numel() for p in net.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hnK96rE_Bq1F",
    "outputId": "4f8b1231-ce04-4918-d773-6146411eb697"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Step [100/938], Loss: 1.5934\n",
      "Epoch [1/3], Step [200/938], Loss: 1.5985\n",
      "Epoch [1/3], Step [300/938], Loss: 1.5435\n",
      "Epoch [1/3], Step [400/938], Loss: 1.4922\n",
      "Epoch [1/3], Step [500/938], Loss: 1.5134\n",
      "Epoch [1/3], Step [600/938], Loss: 1.5082\n",
      "Epoch [1/3], Step [700/938], Loss: 1.5027\n",
      "Epoch [1/3], Step [800/938], Loss: 1.5760\n",
      "Epoch [1/3], Step [900/938], Loss: 1.5309\n",
      "Epoch [2/3], Step [100/938], Loss: 1.4932\n",
      "Epoch [2/3], Step [200/938], Loss: 1.5181\n",
      "Epoch [2/3], Step [300/938], Loss: 1.4820\n",
      "Epoch [2/3], Step [400/938], Loss: 1.5169\n",
      "Epoch [2/3], Step [500/938], Loss: 1.4741\n",
      "Epoch [2/3], Step [600/938], Loss: 1.5075\n",
      "Epoch [2/3], Step [700/938], Loss: 1.4953\n",
      "Epoch [2/3], Step [800/938], Loss: 1.4702\n",
      "Epoch [2/3], Step [900/938], Loss: 1.4894\n",
      "Epoch [3/3], Step [100/938], Loss: 1.4758\n",
      "Epoch [3/3], Step [200/938], Loss: 1.4915\n",
      "Epoch [3/3], Step [300/938], Loss: 1.4864\n",
      "Epoch [3/3], Step [400/938], Loss: 1.4841\n",
      "Epoch [3/3], Step [500/938], Loss: 1.4663\n",
      "Epoch [3/3], Step [600/938], Loss: 1.5066\n",
      "Epoch [3/3], Step [700/938], Loss: 1.4928\n",
      "Epoch [3/3], Step [800/938], Loss: 1.5045\n",
      "Epoch [3/3], Step [900/938], Loss: 1.4834\n"
     ]
    }
   ],
   "source": [
    "# Train the network for 3 epochs\n",
    "for epoch in range(3):\n",
    "    for i, data in enumerate(train_loader):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print statistics\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'.format(\n",
    "                epoch + 1, 3, i + 1, len(train_loader), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "to4kNi78Bu59",
    "outputId": "6450898d-294f-4d7e-a202-e2b41038a66e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 97.58%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the network on the test set\n",
    "net.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = net(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Test Accuracy: {}%'.format((correct / total) * 100))\n",
    "\n",
    "# Save the model\n",
    "torch.save(net.state_dict(), './mnist_net.pth')\n",
    "\n",
    "# Load the model\n",
    "model = Net().to(device)\n",
    "model.load_state_dict(torch.load('./mnist_net.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "kZVCJRp6EV1p"
   },
   "outputs": [],
   "source": [
    "from laplace import Laplace\n",
    "\n",
    "# Examples of different ways to specify the subnetwork\n",
    "# via indices of the vectorized model parameters\n",
    "#\n",
    "# Example 1: select the 128 parameters with the largest magnitude\n",
    "from laplace.utils import LargestMagnitudeSubnetMask\n",
    "subnetwork_mask = LargestMagnitudeSubnetMask(model, n_params_subnet=128)\n",
    "subnetwork_indices = subnetwork_mask.select()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iHm39kWrJn6t",
    "outputId": "d79f819f-7d89-4d21-9b31-09ea8816f613"
   },
   "outputs": [],
   "source": [
    "subnetwork_indices = subnetwork_indices.type(torch.LongTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([      6,       7,      11,      15,      16,      22,      23,      28,\n",
       "             35,      41,      43,      47,      49,      51,      54,      58,\n",
       "             64,      65,      74,      78,      79,      80,      81,      85,\n",
       "             86,      87,      91,      93,      95,      99,     103,     107,\n",
       "            114,     115,     118,     121,     124,     125,     130,     132,\n",
       "            134,     137,     141,     142,     143,     144,     148,     150,\n",
       "            155,     158,     160,     161,     164,     165,     167,     169,\n",
       "            175,     177,     178,     184,     186,     187,     190,     191,\n",
       "            197,     198,     201,     207,     212,     214,     217,     218,\n",
       "            226,     227,     229,     232,     238,     241,     248,     259,\n",
       "            263,     269,     274,     279,     280,     286,     287,    2622,\n",
       "           8454,   12414,   12800,   12989,   14498, 1182795, 1366099, 1591699,\n",
       "        1596399, 2017373, 2502173, 2549493, 2785399, 2785449, 2785471, 2785492,\n",
       "        2785551, 2785656, 2785658, 2785666, 2785691, 2785693, 2785860, 2785868,\n",
       "        2785902, 2785943, 2785960, 2785970, 2785990, 2786001, 2786023, 2786024,\n",
       "        2786026, 2786104, 2786198, 2786230, 2786272, 2786322, 2786343, 2786613])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subnetwork_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "eh9h0k_LEnoR"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ba13/anaconda3/envs/conda-torch/lib/python3.10/site-packages/backpack/extensions/backprop_extension.py:106: UserWarning: Extension saving to grad_batch does not have an extension for Module <class '__main__.Net'> although the module has parameters\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Define and fit subnetwork LA using the specified subnetwork indices\n",
    "la = Laplace(model, 'classification',\n",
    "             subset_of_weights='subnetwork',\n",
    "             hessian_structure='full',\n",
    "             subnetwork_indices=subnetwork_indices)\n",
    "la.fit(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "slhZxgGMVtOk"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 128])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "la.H.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
