{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ba13/anaconda3/envs/conda-torch/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/ba13/anaconda3/envs/conda-torch/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSs'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils import parameters_to_vector\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import Net\n",
    "from hyperparams import _n_params_subnet, _base_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Device configuration\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the MNIST dataset\n",
    "train_dataset = torchvision.datasets.MNIST(root=f'{_base_path}/data', train=True, download=True, transform=transforms.ToTensor())\n",
    "test_dataset = torchvision.datasets.MNIST(root=f'{_base_path}/data', train=False, download=True, transform=transforms.ToTensor())\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = Net().to(device)\n",
    "net.load_state_dict(torch.load(f'{_base_path}/mnist_net.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "subnet_mask_indices = torch.load(f'{_base_path}/subnet_mask_indices.pt').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_dict = {k: v for k, v in net.named_parameters() if v.requires_grad}\n",
    "buffers_dict = {k: v for k, v in net.named_buffers()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']),\n",
       " dict_keys([]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_dict.keys(), buffers_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_params: 214538\n",
      "n_outputs: 10\n"
     ]
    }
   ],
   "source": [
    "net = net.to(device)\n",
    "params_dict = {key: value.to(device) for key, value in params_dict.items()}\n",
    "buffers_dict = {key: value.to(device) for key, value in buffers_dict.items()}\n",
    "\n",
    "n_params = len(parameters_to_vector(net.parameters()).detach())\n",
    "print(\"n_params:\", n_params)\n",
    "\n",
    "H = torch.zeros(_n_params_subnet, _n_params_subnet, device=device)\n",
    "loss = 0\n",
    "n_data = 0\n",
    "net.eval()\n",
    "mean = parameters_to_vector(net.parameters())\n",
    "X, _ = next(iter(train_loader))\n",
    "with torch.no_grad():\n",
    "    try:\n",
    "        out = net(X[:1].to(device))\n",
    "    except (TypeError, AttributeError):\n",
    "        out = net(X.to(device))\n",
    "n_outputs = out.shape[-1]\n",
    "print(\"n_outputs:\", n_outputs)\n",
    "setattr(net, 'output_size', n_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn_params_only(params_dict, buffers_dict):\n",
    "    out = torch.func.functional_call(net, (params_dict, buffers_dict), X)\n",
    "    return out, out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lossfunc = nn.CrossEntropyLoss(reduction='sum')\n",
    "count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: tensor([6], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "X, y = next(iter(train_loader))\n",
    "X, y = X.to(device), y.to(device)\n",
    "print(\"Label:\", y)\n",
    "count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum: tensor(0., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "Count: 1\n"
     ]
    }
   ],
   "source": [
    "net.zero_grad()\n",
    "Js, f = torch.func.jacrev(model_fn_params_only, has_aux=True)(params_dict, buffers_dict)\n",
    "\n",
    "Js = [\n",
    "    j.flatten(start_dim=-p.dim())\n",
    "    for j, p in zip(Js.values(), params_dict.values())\n",
    "]\n",
    "Js = torch.cat(Js, dim=-1)\n",
    "\n",
    "Js = Js[:, :, subnet_mask_indices]\n",
    "print(\"Sum:\", Js.sum())\n",
    "print(Js)\n",
    "print(\"Count:\", count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(train_loader.dataset)\n",
    "i = 0\n",
    "for X, y in train_loader:\n",
    "# X, y = next(iter(train_loader))\n",
    "    i = i + 1\n",
    "    if i % 100 == 0:\n",
    "        print(i)\n",
    "    net.zero_grad()\n",
    "    X, y = X.to(device), y.to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        Js, f = torch.func.jacrev(model_fn_params_only, has_aux=True)(params_dict, buffers_dict)\n",
    "\n",
    "    Js = [\n",
    "        j.flatten(start_dim=-p.dim())\n",
    "        for j, p in zip(Js.values(), params_dict.values())\n",
    "    ]\n",
    "    Js = torch.cat(Js, dim=-1)\n",
    "\n",
    "    Js = Js[:, :, subnet_mask_indices]\n",
    "    print(Js.sum(), Js.shape)\n",
    "\n",
    "\n",
    "    ps = torch.softmax(f, dim=-1)\n",
    "    H_lik = torch.diag_embed(ps) - torch.einsum('mk,mc->mck', ps, ps)\n",
    "    H_batch = torch.einsum('bcp,bck,bkq->pq', Js, H_lik, Js)\n",
    "    loss_batch = 1. * lossfunc(f, y)\n",
    "    loss += loss_batch\n",
    "    H += H_batch\n",
    "    del Js, f, H_lik, H_batch, ps, loss_batch, X, y\n",
    "n_data += N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.distributions.multivariate_normal import _precision_to_scale_tril"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma_noise = 1.\n",
    "temperature = 1\n",
    "sigma_noise = torch.tensor(sigma_noise, device=device)\n",
    "sigma2 = sigma_noise.square()\n",
    "_H_factor = 1 / sigma2 / temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_precision = 1.\n",
    "prior_precision_diag = torch.ones(_n_params_subnet, device=device)\n",
    "posterior_precision = _H_factor * H + torch.diag(prior_precision_diag)\n",
    "# posterior_precision = torch.diag(prior_precision_diag)\n",
    "invsqrt_precision = _precision_to_scale_tril\n",
    "posterior_scale = invsqrt_precision(posterior_precision)\n",
    "scale = posterior_scale\n",
    "posterior_covariance = scale @ scale.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_covariance.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda-torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
