{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ba13/anaconda3/envs/conda-torch/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/ba13/anaconda3/envs/conda-torch/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSs'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.nn.utils.convert_parameters import parameters_to_vector\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Device configuration\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device {device}\")\n",
    "\n",
    "# Load the MNIST dataset\n",
    "train_dataset = torchvision.datasets.MNIST(\n",
    "    root=\"./data\", train=True, download=True, transform=transforms.ToTensor()\n",
    ")\n",
    "test_dataset = torchvision.datasets.MNIST(\n",
    "    root=\"./data\", train=False, download=True, transform=transforms.ToTensor()\n",
    ")\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "        self.fc1 = nn.Linear(32 * 7 * 7, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = x.view(-1, 32 * 7 * 7)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.softmax(self.fc3(x), dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "214538"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the network\n",
    "net = Net().to(device)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters())\n",
    "\n",
    "# model parameters\n",
    "sum(p.numel() for p in net.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Step [10000/60000], Loss: 1.4612\n",
      "Epoch [1/3], Step [20000/60000], Loss: 1.4612\n",
      "Epoch [1/3], Step [30000/60000], Loss: 1.4612\n",
      "Epoch [1/3], Step [40000/60000], Loss: 1.4612\n",
      "Epoch [1/3], Step [50000/60000], Loss: 1.4612\n",
      "Epoch [1/3], Step [60000/60000], Loss: 1.4612\n",
      "Epoch [2/3], Step [10000/60000], Loss: 1.4612\n",
      "Epoch [2/3], Step [20000/60000], Loss: 2.4612\n",
      "Epoch [2/3], Step [30000/60000], Loss: 2.4612\n",
      "Epoch [2/3], Step [40000/60000], Loss: 1.4612\n",
      "Epoch [2/3], Step [50000/60000], Loss: 2.4611\n",
      "Epoch [2/3], Step [60000/60000], Loss: 1.4612\n",
      "Epoch [3/3], Step [10000/60000], Loss: 1.4612\n",
      "Epoch [3/3], Step [20000/60000], Loss: 1.4612\n",
      "Epoch [3/3], Step [30000/60000], Loss: 1.4612\n",
      "Epoch [3/3], Step [40000/60000], Loss: 1.4612\n",
      "Epoch [3/3], Step [50000/60000], Loss: 1.4612\n",
      "Epoch [3/3], Step [60000/60000], Loss: 1.4612\n"
     ]
    }
   ],
   "source": [
    "# Train the network for 3 epochs\n",
    "net.train()\n",
    "for epoch in range(3):\n",
    "    for i, data in enumerate(train_loader):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print statistics\n",
    "        if (i + 1) % 10000 == 0:\n",
    "            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'.format(\n",
    "                epoch + 1, 3, i + 1, len(train_loader), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 92.19000000000001%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the network on the test set\n",
    "net.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = net(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Test Accuracy: {}%'.format((correct / total) * 100))\n",
    "\n",
    "# Save the model\n",
    "torch.save(net.state_dict(), './mnist_net.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the model\n",
    "model = Net().to(device)\n",
    "model.load_state_dict(torch.load(\"./mnist_net.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "_model = deepcopy(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _param_vector(model):\n",
    "    return parameters_to_vector(model.parameters()).detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = torch.zeros_like(_param_vector(_model))\n",
    "sq_mean = torch.zeros_like(_param_vector(_model))\n",
    "n_snapshots = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_snapshots_total = 3\n",
    "snapshot_freq = 1\n",
    "lr = 0.01\n",
    "momentum = 0.9\n",
    "weight_decay = 3e-4\n",
    "min_var = 1e-30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(\n",
    "    _model.parameters(), lr=lr, momentum=momentum, weight_decay=weight_decay\n",
    ")\n",
    "n_epochs = snapshot_freq * n_snapshots_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(i)\n\u001b[1;32m      9\u001b[0m inputs, targets \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(device), targets\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 10\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(_model(inputs), targets)\n\u001b[1;32m     12\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/anaconda3/envs/conda-torch/lib/python3.10/site-packages/torch/_compile.py:24\u001b[0m, in \u001b[0;36m_disable_dynamo.<locals>.inner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(fn)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dynamo\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dynamo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdisable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecursive\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/conda-torch/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:324\u001b[0m, in \u001b[0;36m_TorchDynamoContext.__call__.<locals>._fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m prior \u001b[38;5;241m=\u001b[39m set_eval_frame(callback)\n\u001b[1;32m    323\u001b[0m backend_ctx \u001b[38;5;241m=\u001b[39m backend_ctx_ctor()\n\u001b[0;32m--> 324\u001b[0m \u001b[43mbackend_ctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__enter__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    325\u001b[0m dynamic_ctx \u001b[38;5;241m=\u001b[39m enable_dynamic(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdynamic, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexport)\n\u001b[1;32m    326\u001b[0m dynamic_ctx\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__enter__\u001b[39m()\n",
      "File \u001b[0;32m~/anaconda3/envs/conda-torch/lib/python3.10/contextlib.py:735\u001b[0m, in \u001b[0;36mnullcontext.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    732\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, enter_result\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    733\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menter_result \u001b[38;5;241m=\u001b[39m enter_result\n\u001b[0;32m--> 735\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__enter__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menter_result\n\u001b[1;32m    738\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39mexcinfo):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    print(\"epoch \", epoch)\n",
    "    i = 0\n",
    "    for inputs, targets in train_loader:\n",
    "        i = i + 1\n",
    "        if i % 10000 == 0:\n",
    "            print(i)\n",
    "\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(_model(inputs), targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if epoch % snapshot_freq == 0:\n",
    "        old_fac, new_fac = n_snapshots / (n_snapshots + 1), 1 / (n_snapshots + 1)\n",
    "        mean = mean * old_fac + _param_vector(_model) * new_fac\n",
    "        sq_mean = sq_mean * old_fac + _param_vector(_model) ** 2 * new_fac\n",
    "        n_snapshots += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_variances = torch.clamp(sq_mean - mean**2, min_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_n_params_subnet = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = torch.argsort(param_variances, descending=True)[:32]\n",
    "idx = idx.sort()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_vector = parameters_to_vector(net.parameters()).detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subnet_mask = torch.zeros_like(parameter_vector).bool()\n",
    "subnet_mask[idx] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subnet_mask_indices = subnet_mask.nonzero(as_tuple=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([    47,   2397,   2426,  13590,  15157,  15158,  15163,  15176,  15177,\n",
       "         84149,  84150, 128497, 188819, 188831, 189002, 189003, 189205, 189206,\n",
       "        189210, 189211, 189223, 189224, 189225, 205638, 207942, 209222, 210502,\n",
       "        210630, 210758, 210886, 211654, 214249], device='cuda:0')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.save(subnet_mask_indices, \"subnet_mask_indices.pt\")\n",
    "subnet_mask_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subnet_mask_indices = torch.load(\"./subnet_mask_indices.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying on samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_dict = {k: v for k, v in net.named_parameters() if v.requires_grad}\n",
    "buffers_dict = {k: v for k, v in net.named_buffers()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data_iter = iter(test_loader)\n",
    "x, label_var = next(data_iter)\n",
    "\n",
    "x = x[0]\n",
    "label = label_var[0]\n",
    "\n",
    "image = x.view(28, 28)\n",
    "\n",
    "plt.imshow(image, cmap=\"gray\")\n",
    "plt.title(\"Label: {}\".format(label))\n",
    "plt.axis(\"off\")  # Hide axes\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = net.to(device)\n",
    "params_dict = {key: value.to(device) for key, value in params_dict.items()}\n",
    "buffers_dict = {key: value.to(device) for key, value in buffers_dict.items()}\n",
    "x = x.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn_params_only(params_dict, buffers_dict):\n",
    "    out = torch.func.functional_call(net, (params_dict, buffers_dict), x)\n",
    "    return out, out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_params = len(parameters_to_vector(net.parameters()).detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = 0\n",
    "n_data = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.eval()\n",
    "mean = parameters_to_vector(net.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, _ = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    try:\n",
    "        out = net(X[:1].to(device))\n",
    "    except (TypeError, AttributeError):\n",
    "        out = net(X.to(device))\n",
    "n_outputs = out.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setattr(net, \"output_size\", n_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H = torch.zeros(_n_params_subnet, _n_params_subnet, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jacobians(x):\n",
    "    def model_fn_params_only(params_dict, buffers_dict):\n",
    "        out = torch.func.functional_call(net, (params_dict, buffers_dict), x)\n",
    "        return out, out\n",
    "\n",
    "    with torch.no_grad():\n",
    "        Js, f = torch.func.jacrev(model_fn_params_only, has_aux=True)(\n",
    "            params_dict, buffers_dict\n",
    "        )\n",
    "\n",
    "    Js = [\n",
    "        j.flatten(start_dim=-p.dim()) for j, p in zip(Js.values(), params_dict.values())\n",
    "    ]\n",
    "    Js = torch.cat(Js, dim=-1)\n",
    "\n",
    "    Js = Js[:, :, subnet_mask_indices]\n",
    "    return Js, f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import CrossEntropyLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(train_loader.dataset)\n",
    "i = 0\n",
    "for X, y in train_loader:\n",
    "    i = i + 1\n",
    "    if i % 1000 == 0:\n",
    "        print(i)\n",
    "    net.zero_grad()\n",
    "    X, y = X.to(device), y.to(device)\n",
    "    Js, f = jacobians(X)\n",
    "    ps = torch.softmax(f, dim=-1)\n",
    "    H_lik = torch.diag_embed(ps) - torch.einsum(\"mk,mc->mck\", ps, ps)\n",
    "    H_batch = torch.einsum(\"bcp,bck,bkq->pq\", Js, H_lik, Js)\n",
    "    lossfunc = CrossEntropyLoss(reduction=\"sum\")\n",
    "    loss_batch = 1.0 * lossfunc(f, y)\n",
    "    loss += loss_batch\n",
    "    H += H_batch\n",
    "    del X, y, H_lik, H_batch, loss_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 700.3990, -125.4198,  -42.3684,  ...,  -59.6776,  108.0632,\n",
       "           41.5271],\n",
       "        [-125.4198,  210.7474,   47.9255,  ...,   43.1763,  -79.8304,\n",
       "          -33.4819],\n",
       "        [ -42.3684,   47.9255,   41.5851,  ...,   11.4937,  -34.4630,\n",
       "          -14.6852],\n",
       "        ...,\n",
       "        [ -59.6776,   43.1763,   11.4937,  ...,   58.4023,  -34.7992,\n",
       "            6.0773],\n",
       "        [ 108.0632,  -79.8304,  -34.4630,  ...,  -34.7992,  294.4118,\n",
       "          225.3453],\n",
       "        [  41.5271,  -33.4819,  -14.6852,  ...,    6.0773,  225.3453,\n",
       "          358.3875]], device='cuda:0')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma_noise = 1.0\n",
    "temperature = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma_noise = torch.tensor(sigma_noise, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma2 = sigma_noise.square()\n",
    "_H_factor = 1 / sigma2 / temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.distributions.multivariate_normal import _precision_to_scale_tril"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 32])\n"
     ]
    }
   ],
   "source": [
    "prior_precision = 1.\n",
    "prior_precision_diag = torch.ones(_n_params_subnet, device=device)\n",
    "posterior_precision = _H_factor * H + torch.diag(prior_precision_diag)\n",
    "# posterior_precision = torch.diag(prior_precision_diag)\n",
    "invsqrt_precision = _precision_to_scale_tril\n",
    "posterior_scale = invsqrt_precision(posterior_precision)\n",
    "scale = posterior_scale\n",
    "posterior_covariance = scale @ scale.T\n",
    "print(posterior_covariance.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_iter = iter(train_loader)\n",
    "x, label_var = next(data_iter)\n",
    "x = x[0]\n",
    "label = label_var[0]\n",
    "\n",
    "image = x.view(28, 28)\n",
    "\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.title('Label: {}'.format(label))\n",
    "plt.axis('off')  # Hide axes\n",
    "plt.show()\n",
    "\n",
    "\n",
    "x = x.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0853, 0.0853, 0.0853, 0.0853, 0.0853, 0.0853, 0.0853, 0.0853, 0.0853,\n",
      "         0.2320]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    Js, f_mu = torch.func.jacrev(model_fn_params_only, has_aux=True)(params_dict, buffers_dict)\n",
    "\n",
    "Js = [\n",
    "    j.flatten(start_dim=-p.dim())\n",
    "    for j, p in zip(Js.values(), params_dict.values())\n",
    "]\n",
    "Js = torch.cat(Js, dim=-1)\n",
    "\n",
    "Js = Js[:, :, subnet_mask_indices]\n",
    "\n",
    "Js = Js.squeeze(0)\n",
    "f_var = torch.einsum('np,pq,mq->nm', Js, posterior_covariance, Js)\n",
    "f_var = f_var.unsqueeze(0)\n",
    "kappa = 1 / torch.sqrt(1. + torch.pi / 8 * f_var.diagonal(dim1=1, dim2=2))\n",
    "final_ppd = torch.softmax(kappa * f_mu, dim=-1)\n",
    "print(final_ppd)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda-torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
